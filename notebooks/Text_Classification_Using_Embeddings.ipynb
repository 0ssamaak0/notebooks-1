{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Text Classification Using Embeddings.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Text Classification Using Embeddings\n",
    "This notebook shows how to build a classifiers using Cohere's embeddings.\n",
    "<img src=\"https://github.com/cohere-ai/notebooks/raw/main/notebooks/images/simple-classifier-embeddings.png\"\n",
    "alt=\"first we embed the text in the dataset, then we use that to train a classifier\"/>\n",
    "\n",
    "The example classification task here will be sentiment analysis of film reviews. We'll train a simple classifier to detect whether a film review is negative (class 0) or positive (class 1).\n",
    "\n",
    "We'll go through the following steps:\n",
    "\n",
    "1. Get the dataset\n",
    "2. Get the embeddings of the reviews (for both the training set and the test set).\n",
    "3. Train a classifier using the training set\n",
    "4. Evaluate the performance of the classifier on the testing set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XdM6oEyo9oUp"
   },
   "source": [
    "# Let's first install Cohere's python SDK\n",
    "!pip install cohere"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0DIiCJoe_-_"
   },
   "source": [
    "## 1. Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bAVd49D6BjGK"
   },
   "source": [
    "import pandas as pd\n",
    "# Get the SST2 training and test sets\n",
    "df_train = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)\n",
    "df_test = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/test.tsv', delimiter='\\t', header=None)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BYhG9GO3B_Gd",
    "outputId": "f108c462-1a7d-48c1-8153-d1a3c516bff4"
   },
   "source": [
    "# Let's glance at the dataset\n",
    "df_train.head()\n",
    "print(f\"Review #1 text: {df_train.iloc[0, 0]}\")\n",
    "print(f\"Review #1 class: {df_train.iloc[0, 1]}\")\n",
    "print(f\"Review #2 text: {df_train.iloc[1, 0]}\")\n",
    "print(f\"Review #2 class: {df_train.iloc[1, 1]}\")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Review #1 text: a stirring , funny and finally transporting re imagining of beauty and the beast and 1930s horror films\n",
      "Review #1 class: 1\n",
      "Review #2 text: apparently reassembled from the cutting room floor of any given daytime soap\n",
      "Review #2 class: 0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KIMt6G7dlGC"
   },
   "source": [
    "We'll only use a subset of the training and testing datasets in this example. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "z_JwX-OQPN_c"
   },
   "source": [
    "n_train_samples = 500\n",
    "n_test_samples = 500\n",
    "\n",
    "# Sample from the dataset\n",
    "train = df_train.sample(n_train_samples)\n",
    "test = df_test.sample(n_test_samples)\n",
    "\n",
    "sentences_train = list(train.iloc[:,0].values)\n",
    "sentences_test = list(test.iloc[:,0].values)\n",
    "\n",
    "labels_train  = list(train.iloc[:,1].values)\n",
    "labels_test  = list(test.iloc[:,1].values)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aymSE9YFEymy"
   },
   "source": [
    "## 2. Get the embeddings of the reviews\n",
    "We're now ready to retrieve the embeddings from the API"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qqfWFS1RDE54"
   },
   "source": [
    "# import cohere, and start a client session\n",
    "import cohere\n",
    "co = cohere.Client(\"\") # ADD YOUR API KEY HERE\n",
    "\n",
    "# embed sentences from both train and test set on baseline-shrimp\n",
    "embeddings_train = co.embed(model='baseline-shrimp', texts=sentences_train).embeddings\n",
    "embeddings_test = co.embed(model='baseline-shrimp', texts=sentences_test).embeddings"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhg6HkuXeFF_"
   },
   "source": [
    "We now have two sets of embeddings, `embeddings_train` contains the embeddings of the training  sentences while `embeddings_test` contains the embeddings of the testing sentences.\n",
    "\n",
    "Curious what an embedding looks like? we can print it:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AFWgw-l7eXRG",
    "outputId": "7e0572d3-7e94-437e-8cf1-55be7f0e3ecf"
   },
   "source": [
    "print(f\"Review text: {sentences_train[0]}\")\n",
    "print(f\"Embedding vector: {embeddings_train[0]}\")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Review text: its metaphors are opaque enough to avoid didacticism , and the film succeeds as an emotionally accessible , almost mystical work\n",
      "Embedding vector: [0.6579068, 0.16875336, 0.4072475, -0.94259065, 0.6713255, -0.38336453, -1.2589791, -0.5653332, 0.14386642, 0.5655985, -0.24851555, 0.5713835, 0.39206874, 0.8174008, -0.26184016, -1.1561943, 0.23619102, -0.3591043, -0.77078646, -1.963628, 0.8563678, 0.12427265, -1.9898235, -0.22819875, 0.11939957, 0.5999593, 0.25658482, -0.3031655, -0.088325396, -0.10845581, 0.811858, 0.93025625, 0.6680047, -1.010159, -0.4077053, -0.22306879, -0.06685991, -1.5153711, -0.9042679, -0.9925903, 0.508977, -1.2123089, -0.75614417, 0.992275, 0.95189476, -0.5295757, -1.7159832, -0.16067825, -0.22996473, 0.5751526, -1.0977967, 0.11184283, -0.42436096, 0.6324947, -0.64518857, 0.07545187, -0.22488812, 0.3991404, -0.15333608, 0.47543943, 0.072336696, 0.038673982, -0.41471612, -0.15128434, -0.25229073, 0.6113767, -0.27524865, 1.3870261, -0.72940207, -0.87819695, -0.7419976, 1.249976, -0.893421, 0.23341402, 1.1193789, -0.053954978, 0.023064965, 0.61271113, -0.47678202, -0.15387353, 0.22193971, -0.86235666, -0.5368706, 0.52466863, 1.6287713, 0.77481544, -0.04555527, -0.78178805, 0.8555378, -0.49245408, -0.20443282, -0.6285492, -0.12874176, -0.43581718, -0.34790212, 1.3026643, -0.084934235, 0.2388869, -0.29725093, -0.4872287, 0.38169956, -0.039371256, 0.527863, -0.510271, -0.076604515, 0.6917542, -1.1664805, -1.0870992, 0.5125714, -1.1107328, 1.1619526, 0.98966867, -0.45486087, -0.3543715, 0.9618023, 1.0972536, 0.7024417, -0.23378016, 0.8064031, 0.16557953, 0.6037093, -0.49617535, -0.79252315, -0.89583707, 0.6015685, -0.78221154, 1.0674282, -0.5279064, -0.34534878, 0.0224159, 0.5366194, -0.2911005, 0.7402291, -0.3679248, 0.14069287, -1.8994362, -0.5147772, 2.6876285, -0.61360836, -0.47164696, -0.3841607, -1.0282553, -0.7274109, 0.12973279, 0.10780776, 1.1185738, 0.097678296, -0.57067835, -0.16668598, -0.3271528, 0.6083872, 0.9195334, -0.9744906, -0.29310918, -1.6263012, -0.5021161, 0.013576014, 0.5441832, 0.6406029, 1.0926555, -0.35478562, -1.3233685, -0.16127738, -1.2579595, -0.37175012, -1.0474286, -1.187914, -1.2486572, -1.699955, -0.078121446, 0.7204458, -0.84352446, -0.28773427, -0.6446573, -0.6536672, -0.2930509, 1.3339403, -1.2570385, -0.7744133, -0.5885378, 0.18522969, -1.2305782, 0.20029327, -0.40625703, -0.29776326, 1.4022985, 0.17832191, 0.3072566, 0.71967775, 0.32533452, -0.07867973, 0.29098737, -0.7842181, -0.0017715964, 1.2996383, -0.21467161, -1.2389956, 0.10264809, 1.0171448, 0.25119847, 0.55688596, 0.5719819, -1.2665684, 0.78436685, 0.43094352, 0.32030538, 2.2032566, 1.0075318, 0.26412055, 0.51461565, -0.39768052, 0.26483682, 0.2839334, 0.086673565, 0.65342087, 1.3151321, 0.4659518, 1.015222, -0.87463737, 0.3443624, 0.79594684, 0.037579495, 0.25386083, 0.82425207, -0.79899496, 0.18861353, 0.07680522, 0.22408754, 1.3950163, -0.527846, 0.2997947, 0.8548764, -0.2440963, 0.38003173, 0.46959916, 0.30713186, -0.5860894, -0.28402913, -1.520372, 0.7169018, 1.0658793, 0.27450362, -1.6038136, -0.19400325, -0.9522728, -2.0709136, 0.60126096, 0.13248768, 0.22094291, -0.6674113, 0.14275497, -0.32427353, 0.20942856, 1.0048245, 0.27358502, 0.6538464, -0.24254212, 0.7335872, 1.1583437, -0.68846357, -0.2158061, -0.15439571, -1.4657125, 1.8498864, -1.1937606, -0.21051466, 1.0310469, 0.54243016, 0.33956897, -0.975225, 0.25105307, -0.13084927, 1.7741113, 0.8731604, -1.2856184, 0.4848373, -1.1162038, 2.6900077, -0.7166562, -0.063186385, 1.1801554, -0.16825998, -0.5244772, -0.18626031, -0.11884031, -1.1743574, -1.2876586, -0.7839685, -0.2232162, -0.42206505, 0.2870016, 0.12261026, -0.9603282, -0.109542124, 0.6816889, 0.2538364, -0.4897866, -1.5244608, 0.5890413, 1.0667634, -1.4596574, 0.26191595, 0.49183738, -0.33846104, -1.3072053, -0.6856747, 0.3662763, -0.18743858, 0.3373649, 1.3128432, 0.3117891, -0.042395044, 1.1282309, 0.07416464, 0.21071023, 0.19896677, -0.8182946, -0.30735993, 0.62345904, -1.0993886, 1.6762874, -0.4311491, -1.1188056, -0.26734483, 0.73083174, 1.312799, -0.4092231, 2.4623075, -0.5372666, -0.66107315, 0.1903207, 0.37248683, -0.27991965, -0.46899322, -0.35160974, 1.6079605, 1.0061587, 1.4407718, -0.17146637, -0.06682986, -0.97913384, -0.29100522, -0.04939907, -0.8321912, -1.0393641, -0.6544565, -0.5625706, -0.57291526, -0.87826675, -0.036098707, -0.32835346, 0.8995968, 0.74483496, -0.35636237, 0.2565266, 1.0660223, -1.0576248, -0.67193174, 0.21734042, 0.5889573, 0.74386567, 0.25119022, -0.86877793, -1.4026222, -0.5189989, -0.61232406, 0.018635921, -0.76290286, 0.99605256, -1.4030426, -0.31397697, 0.2606579, 0.449157, -0.9383613, 0.52549267, -0.61421055, -0.122220494, -0.8410022, -1.0547013, 0.08746366, -0.7688538, 0.36346257, -0.23736404, -0.6110622, -0.3710391, 0.43433812, 0.6332101, -0.2331197, 0.46051016, 0.5097709, -0.4981999, -0.07945749, 0.9512613, -0.22595753, -1.0808123, 0.02830888, -1.3383918, -0.26857942, -0.27637893, -0.8030619, -0.21413717, 1.4279372, 2.299745, 0.44661495, -0.5360012, 0.47819203, -1.1131719, 1.03238, 0.08350488, -0.49087542, -0.24604402, -0.5501776, -0.48343322, -1.08091, 0.66747236, -1.9633412, 0.049381923, 0.49910888, 1.0805093, 0.12123162, 0.6758139, -0.3560282, -1.001532, -0.7268919, -1.5102696, -0.58786416, -0.8728046, -0.7525419, 0.37774277, -0.14835815, -0.1986283, -1.0690991, -0.66818863, -0.20940623, 1.6966984, -0.08376026, 0.31237817, 0.34679824, 0.93715745, 0.089887716, 0.09489043, -1.9335023, -0.26888612, -1.0774692, -0.06333774, -0.6150058, 0.27320257, 1.0104431, -1.0336248, 0.48651806, -0.8134137, -0.7971432, 0.40643784, -0.9922831, -0.38666847, -0.551229, 0.47970885, -0.942117, 0.84965795, 0.5486325, 0.75958216, 0.056143798, 1.8883556, -0.45179465, -0.25738972, -1.513494, 1.2092518, -1.3936044, -1.0968318, 2.3188016, 0.054557644, -0.68800646, -1.4260149, 0.97273064, 0.23069023, -0.2816982, -0.6211736, -0.7131631, -0.40505517, -0.054722752, 0.150444, 0.06801242, -0.7676828, -0.74947256, 0.024542289, 1.6016618, -1.0806737, 0.054086424, -0.7155024, -1.2611365, -0.6854098, -0.04834344, -0.61383355, 0.14863554, -0.6485391, -0.6422449, 0.056324564, -1.1484443, -0.24312107, -0.43164447, -0.41633263, -1.4752743, -0.45062897, 0.84602195, -0.5983657, 1.1408553, 0.5042348, 0.3086224, 1.2096897, -0.8004474, 1.5232921, 0.12560345, 0.18312602, 0.03705519, 0.11731693, 0.9464237, 0.22345303, 1.4746284, -0.063224666, 0.5668259, 0.6221756, 1.3144535, 0.3907619, -0.31436893, 0.37212402, -0.74534637, -0.16666569, -0.9227632, 0.7330379, -1.361398, 1.210187, 0.50058067, 1.8767786, 0.25319046, -0.3263718, -0.30676898, 0.3490206, 0.42385352, 0.18095893, -0.52914125, -0.5026379, -0.7157121, 1.188699, 0.03587316, 0.0012644887, 1.159829, -0.54043394, 0.26035568, 0.6181149, -0.9439834, -0.12955345, -0.30437642, 0.63952714, -0.19390024, -0.45286164, 0.27728063, 1.213961, -1.3201191, -1.517274, -0.6026757, -0.017654382, 0.056875933, 1.4812481, 1.665361, 0.779344, -0.8165438, 0.31523818, -0.2648844, -0.14683132, 0.13971637, 0.23420708, 0.18987375, -1.6988461, -0.92761344, 0.5482827, -0.7065312, 1.2081839, 0.7081455, -0.8113762, -0.569347, -0.2691257, 1.0191383, 1.077971, 0.47361958, -0.59477305, 0.10586756, 0.033145197, 1.2093196, 0.82384944, 0.46273494, -0.24406299, 0.51083136, -0.45689666, 0.14068419, -1.4145855, 1.4322299, 0.30890232, -0.86604655, -0.102279924, -1.3232253, -0.18475251, 0.061014324, 0.038215872, -1.1393619, -0.69294256, 0.5155519, -0.10374716, -0.3052177, -1.1229798, 0.33061203, 1.2461029, 1.1758957, 0.65327674, 0.08557667, -0.323428, 0.051750783, -0.66350096, 0.08642485, -0.016736148, 0.30120173, -0.2036446, -0.1084234, 0.2961911, 1.5582775, -1.7790309, 1.1923923, -1.1151606, -0.13503489, 0.6143148, -1.4039776, 0.61362594, -0.32972893, 0.28028184, 0.9337232, -0.6328992, 0.9913568, 0.37016124, 0.44017696, -0.2323088, 1.4427207, -0.45590758, -0.49677375, 0.119832724, -0.22184016, -0.007063346, -1.6708844, 0.4237505, -1.5386183, -0.22652934, -1.2549467, -0.087219454, 0.937079, 0.34926596, -1.5771466, 0.5847857, -0.5181248, 1.2904199, -0.15629569, -1.6187476, -1.0159636, -0.8469369, -0.062059708, -0.6969155, 0.6880463, -0.39402786, 0.18883494, -0.8427783, -1.3343878, -0.6229588, 0.06067173, -0.8187656, -0.3742369, 0.7904998, -0.92365766, 1.3516479, 0.31116617, 1.2337083, -0.028227849, 0.5193476, 0.033122636, -0.28781998, 2.0115724, 0.87717324, 0.8313882, 0.0202642, 1.3404553, 0.25544864, -1.4255791, -0.26026657, -1.161584, 0.5989353, 0.368794, 0.5861715, 0.7553629, -1.7578497, -0.051605362, 0.14368072, 0.16905323, -0.19520618, -1.2229557, 0.34668687, 0.009385063, -0.821465, 1.065098, -1.0935193, -0.39615232, -0.73085195, 1.2843512, 0.47411424, 0.47810382, -0.43477765, -0.0008226872, 0.42797458, 0.20266712, 1.6962166, -0.09340971, 0.19051757, 0.33694255, 0.7930598, -0.817619, -0.49993724, -0.13638175, -0.0007768729, -0.26354036, -0.6857913, 0.43107656, -0.5514091, 0.44200554, -0.77278054, 0.011953815, 0.24148327, -0.20357467, 0.42460683, -0.08471611, 1.7165505, -0.52635664, -0.28220168, 0.03487011, -0.21836779, 1.3176193, 0.67928267, -1.4054829, -0.3786518, 0.23988585, -0.28542116, 0.9795816, -0.48036355, 1.4562349, 0.078522265, -0.24977127, -1.1814806, 0.8767065, -1.58375, -0.7031479, -0.122466795, -0.081805155, -0.204845, -0.28717983, 0.09883827, 1.0731328, 0.3750886, -0.9219699, -0.5382213, 0.7119996, 0.26434955, 0.45771965, -1.9702182, 0.86011386]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTjZkSXEeoMB"
   },
   "source": [
    "## 3. Train a classifier using the training set\n",
    "Now that we have the embedding we can train our classifier. We'll use an SVM from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1FGyYoHSCK03",
    "outputId": "f3c99cb8-8ba7-4c61-ce93-b3274530c29d"
   },
   "source": [
    "# import support vector machine code\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# initialize the support vector machine, with class_weight='balanced' because \n",
    "# our training set has roughly an equal amount of positive and negative \n",
    "# sentiment sentences\n",
    "svm_classifier = make_pipeline(StandardScaler(), SVC(class_weight='balanced')) \n",
    "\n",
    "# fit the support vector machine\n",
    "svm_classifier.fit(embeddings_train, labels_train)\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('svc',\n",
       "                 SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                     class_weight='balanced', coef0=0.0,\n",
       "                     decision_function_shape='ovr', degree=3, gamma='scale',\n",
       "                     kernel='rbf', max_iter=-1, probability=False,\n",
       "                     random_state=None, shrinking=True, tol=0.001,\n",
       "                     verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VuAjDXjzfWJ7"
   },
   "source": [
    "## 4. Evaluate the performance of the classifier on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NrHAN510fWlm",
    "outputId": "d41f6bf0-a912-4e58-84a6-cf58572d5fa8"
   },
   "source": [
    "# get the score from the test set, and print it out to screen!\n",
    "score = svm_classifier.score(embeddings_test, labels_test)\n",
    "print(f\"Validation accuracy on baseline-shrimp is {100*score}%!\")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation accuracy on baseline-shrimp is 84.8%!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WnfBgA-OkKL"
   },
   "source": [
    "Let's try increasing the size of the model, and using baseline-otter instead to see if we can improve our score."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CSMqRRwT9mrh"
   },
   "source": [
    "\n",
    "# embed sentences from both train and test set on baseline-otter\n",
    "embeddings_train = co.embed(model='baseline-otter', texts=sentences_train).embeddings\n",
    "embeddings_test = co.embed(model='baseline-otter', texts=sentences_test).embeddings\n",
    "# run the same process as before\n",
    "svm_classifier = make_pipeline(StandardScaler(), SVC(class_weight='balanced')) \n",
    "svm_classifier.fit(embeddings_train, labels_train)\n",
    "score = svm_classifier.score(embeddings_test, labels_test)\n",
    "print(f\"Validation accuracy on baseline-otter is {100*score}%!\")\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mqm64NiSgcAt"
   },
   "source": [
    "With a bigger model, we can further improve the accuract score! This trend typically holds: bigger models tend to create\n",
    "more semantically rich embeddings, that can be used to solve a wider variety of downstream tasks. \n",
    "\n",
    "This was a small scale example, meant as a proof of concept, and designed to illustrate how you can build a custom\n",
    "classifier quickly using a small amount of labelled data and Cohere's embeddings. "
   ]
  }
 ]
}