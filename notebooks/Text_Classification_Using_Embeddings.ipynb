{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Copy of Text Classification Using Embeddings.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "V4B-KoWi1HDP"
   },
   "source": [
    "# Text Classification Using Embeddings\n",
    "This notebook shows how to build a classifiers using Cohere's embeddings.\n",
    "<img src=\"https://github.com/cohere-ai/notebooks/raw/main/notebooks/images/simple-classifier-embeddings.png\"\n",
    "style=\"width:100%; max-width:600px\"\n",
    "alt=\"first we embed the text in the dataset, then we use that to train a classifier\"/>\n",
    "\n",
    "The example classification task here will be sentiment analysis of film reviews. We'll train a simple classifier to detect whether a film review is negative (class 0) or positive (class 1).\n",
    "\n",
    "We'll go through the following steps:\n",
    "\n",
    "1. Get the dataset\n",
    "2. Get the embeddings of the reviews (for both the training set and the test set).\n",
    "3. Train a classifier using the training set\n",
    "4. Evaluate the performance of the classifier on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XdM6oEyo9oUp"
   },
   "source": [
    "# Let's first install Cohere's python SDK\n",
    "!pip install cohere"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0DIiCJoe_-_"
   },
   "source": [
    "## 1. Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bAVd49D6BjGK"
   },
   "source": [
    "import pandas as pd\n",
    "# Get the SST2 training and test sets\n",
    "df_train = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)\n",
    "df_test = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/test.tsv', delimiter='\\t', header=None)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BYhG9GO3B_Gd",
    "outputId": "e16f74d7-f6b1-44a6-db0b-49f21a3862e6"
   },
   "source": [
    "# Let's glance at the dataset\n",
    "df_train.head()\n",
    "print(f\"Review #1 text: {df_train.iloc[0, 0]}\")\n",
    "print(f\"Review #1 class: {df_train.iloc[0, 1]}\")\n",
    "print(f\"Review #2 text: {df_train.iloc[1, 0]}\")\n",
    "print(f\"Review #2 class: {df_train.iloc[1, 1]}\")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Review #1 text: a stirring , funny and finally transporting re imagining of beauty and the beast and 1930s horror films\n",
      "Review #1 class: 1\n",
      "Review #2 text: apparently reassembled from the cutting room floor of any given daytime soap\n",
      "Review #2 class: 0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KIMt6G7dlGC"
   },
   "source": [
    "We'll only use a subset of the training and testing datasets in this example. We'll only use 100 examples since this is a toy example. You'll want to increase the number to get better performance and evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "z_JwX-OQPN_c"
   },
   "source": [
    "n_train_samples = 100 # Increase for better performance (e.g. 500)\n",
    "n_test_samples = 100 # increase for better evaluation (e.g. 500)\n",
    "\n",
    "# Sample from the dataset\n",
    "train = df_train.sample(n_train_samples)\n",
    "test = df_test.sample(n_test_samples)\n",
    "\n",
    "sentences_train = list(train.iloc[:,0].values)\n",
    "sentences_test = list(test.iloc[:,0].values)\n",
    "\n",
    "labels_train  = list(train.iloc[:,1].values)\n",
    "labels_test  = list(test.iloc[:,1].values)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aymSE9YFEymy"
   },
   "source": [
    "## 2. Get the embeddings of the reviews\n",
    "We're now ready to retrieve the embeddings from the API"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qqfWFS1RDE54"
   },
   "source": [
    "# import cohere, and start a client session\n",
    "import cohere\n",
    "co = cohere.Client(\"\") # ADD YOUR API KEY HERE\n",
    "\n",
    "# embed sentences from both train and test set on baseline-shrimp\n",
    "embeddings_train = co.embed(model='baseline-shrimp', texts=sentences_train).embeddings\n",
    "embeddings_test = co.embed(model='baseline-shrimp', texts=sentences_test).embeddings"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhg6HkuXeFF_"
   },
   "source": [
    "We now have two sets of embeddings, `embeddings_train` contains the embeddings of the training  sentences while `embeddings_test` contains the embeddings of the testing sentences.\n",
    "\n",
    "Curious what an embedding looks like? we can print it:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AFWgw-l7eXRG",
    "outputId": "f958e3ff-f6b0-457b-d0e9-9acad20a7e4e"
   },
   "source": [
    "print(f\"Review text: {sentences_train[0]}\")\n",
    "print(f\"Embedding vector: {embeddings_train[0]}\")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Review text: there 's a sheer unbridled delight in the way the story unfurls\n",
      "Embedding vector: [0.3060446, -0.5590798, 1.3441724, -0.31918874, 0.10319942, -0.611176, -0.45803407, -0.922121, 0.46373415, 0.82814246, -0.7204705, -0.085331775, -0.24679375, 0.33021235, 0.34427735, 0.016704587, 0.21665218, 0.99444443, -1.1864822, -1.2618482, 0.56724435, -0.40024626, -1.1538417, 0.028833997, 0.018415181, -0.70796496, -0.50904775, -0.46730208, -0.8696139, -0.11697644, 0.36991414, 1.8658482, -0.18236113, 0.086177096, 0.5138425, 0.3988735, -1.7110026, 0.12344775, 0.9969331, -1.2200501, 1.3504177, -0.41682506, 0.52232707, 0.713298, 0.6877792, -0.43937904, 0.2173301, -0.41831672, -1.5772377, -0.3469063, -0.04403664, 0.7759863, -0.8057619, -0.5124225, 0.38261724, 0.24261853, 0.434947, 0.8528693, -0.53545344, -0.45064825, -1.603972, 0.7302793, 0.5154807, 0.60574394, -1.3626307, 0.56966937, -1.918972, 0.056056302, -0.5665736, -0.8589762, 0.8349136, 0.5967386, -0.30615053, -0.19666299, -0.25781697, -0.05331686, -1.1098589, -0.32042387, -0.9720702, -0.27332574, -1.9863131, -0.9366798, -0.90494436, -0.21510318, -0.68446404, -0.2630344, -0.82492495, -0.5450464, 0.0095382845, -0.40208802, -2.0707152, -0.60572875, 0.5816881, -0.50049543, -0.93063205, 1.8827835, -1.0312827, -1.0234662, -0.17820929, 0.69070613, 0.7663592, 0.093929246, -0.7966455, 0.22606745, 0.1108831, 0.21451396, -0.27444813, -0.92652816, 0.5931167, 0.9863564, -0.8562563, 0.10184361, 0.47461337, 0.2833498, -0.56436145, 1.3280746, -1.2091335, 0.77733564, -0.37950337, 1.1167333, 0.20257173, 1.3859892, -1.8480022, 0.058995374, -0.37598395, -1.2068266, -0.916592, -0.447314, 0.7371153, -0.34732538, 0.57014424, -0.19702293, -0.21733665, -0.30430022, -0.42486638, -0.08776649, 0.8012543, 1.3650198, 0.41860524, 0.40329778, -1.406238, -0.48762384, 0.8971894, -0.7295497, -0.7554483, 1.0872701, -0.7759671, -1.0818564, 0.6490641, -0.97675806, -0.26002526, 1.3486992, 1.2219288, 0.036433835, -0.25529897, -0.7422129, -0.11817908, 1.7492951, 0.09415211, 0.64315885, 0.30821812, 0.24836038, -0.75168574, -0.7721443, -0.1957133, -0.123123586, -0.39080837, -0.7174933, -0.13248275, -2.0233612, -0.21450195, -1.1426042, -0.50488776, -1.1600037, -0.6108776, -0.10434557, 2.1859944, -1.3032345, 0.7491204, -0.62615335, 0.14411286, -0.3186799, 0.59615344, -0.03456662, 0.10195346, 0.6200802, 0.7533857, -0.42633387, 0.66045916, 1.0135629, -0.4787896, 0.81832504, -1.1853933, -0.2802977, 0.50267816, 0.55430055, 0.24324717, -0.6554803, 1.6500723, 0.36667785, 0.88786405, 1.8950566, -0.29052755, -0.7549539, -0.2889775, -1.8827367, 0.96310896, -0.79704064, 0.5776781, -0.9224338, 0.22992566, 0.18130109, 2.0288227, 0.25768787, -0.75475544, -1.3128538, -0.3721465, 0.08378636, -0.0059631574, -0.7518905, -0.8786683, 0.32362023, -0.03063569, 0.43905517, 0.10980744, 0.16908842, -0.101695575, -0.013378431, 0.7649427, 0.17821828, -1.4443129, 0.96315765, -0.429854, 0.1443889, -0.80827266, 0.10380002, 0.45616958, 0.1942787, -1.1535774, 0.43834552, 1.4218744, -0.46263683, -1.202733, -0.5051155, -0.72559154, -0.8126962, 0.55599725, 0.45278618, -0.45237178, 0.33195058, -1.1747328, -0.48971137, -0.3958898, -0.0697058, 0.8786704, -0.09102117, -0.33517414, 1.432177, 0.8190356, 0.043623377, -1.1333232, -0.30707294, -0.7884517, 0.6465413, -0.35237908, 0.008313414, -0.06737323, 0.20021528, 1.0593206, -1.6675698, -0.13978697, 0.03460445, 0.69570524, -0.2410531, -2.6096058, 1.2953657, -0.30034852, 2.634968, 0.2622269, -0.6497824, -0.0036814387, -0.89324576, -0.493363, -0.5338873, 0.16300106, -0.88376683, 0.2271229, -0.63204193, -0.42384923, -0.014017697, -0.27228504, -2.3469245, -0.16118385, -0.6313055, 1.0777032, 0.1960069, -1.1982944, 0.31954822, 0.99610376, 1.826786, -0.44391686, -0.83404917, -0.48522308, -0.116835035, -0.4389583, -0.3788154, -0.81533253, 0.22660142, 1.0810788, 0.6684071, -1.0586635, -1.1215214, -0.07063004, 0.95710933, 0.7128199, 0.9639389, 0.85498095, -2.0108907, 0.5537328, -1.268958, 1.6750802, 0.15544552, -0.59572977, -2.3964636, 0.75645256, 0.67210644, 0.7443787, 0.76266867, -1.1298057, -1.5032508, -0.13947646, 1.010056, -0.3132408, -1.3060656, -0.1402005, 0.5608318, -1.0603126, 0.4932942, 0.21268219, 0.6631475, -1.1464404, -1.7300807, -0.76212794, 0.16291037, 0.21117151, 0.16394179, -0.6621276, -0.47245866, -0.39588544, -0.33830371, -0.79620486, 0.16653901, 1.4318997, 0.18054362, 0.23593134, 0.42239714, -1.3289002, -0.7514664, -0.41362858, 0.0703685, 0.030458137, 1.4412682, 0.933847, -1.197126, -0.10088863, -0.6607397, -2.1222227, 0.45827138, -1.8729587, 0.1822268, 1.0560278, -0.32427812, 0.5217141, -0.91069144, -0.6720221, 0.6994511, 0.13248087, -1.5835503, -0.17996596, -0.4346897, -0.67485625, -0.85437924, 0.682304, -0.31396317, 0.4083004, 0.6352906, -0.18134086, -0.30004495, 0.90933317, -0.84913486, -1.3906214, -0.32903618, 0.30868357, -0.5506084, -0.38572603, -0.32920253, -0.75849074, 0.007921535, 0.009902432, -0.4381507, -0.15843955, 0.19024566, -0.42478096, 0.0629621, 0.724811, 0.79190636, 0.6513708, 1.5615473, 0.18207426, 1.0825148, 0.9549114, -0.07000772, 0.29403713, -1.028756, 0.2658608, -0.013363715, 0.10906196, -0.9011477, -0.05267329, -0.5012017, 0.6441668, -0.44918144, -1.4469776, -0.57804364, -0.8588691, 1.6434454, -0.92672914, 0.30514303, 0.2353262, -0.258028, -0.6393497, -0.45293033, -0.15682912, 0.6178919, 0.50556105, -0.22421081, 1.2911139, -0.23843095, -0.37778774, -1.1035712, 0.50454086, 0.30913347, 0.18057618, -0.11744642, -1.131388, 0.40730527, -0.7065976, 0.9282399, -0.5617705, 0.531681, -0.7528138, -0.6827839, -0.052751053, -1.0577615, -0.42833722, -0.89591736, 0.27255648, -1.611546, -0.21895039, 0.5189225, 0.13918717, -0.58342105, 1.4989777, -1.7435253, 0.3347975, -0.848029, 1.728259, 0.006125443, 0.9704278, -0.14487216, -2.4429114, 0.19868103, -0.44271052, 1.6103891, -0.21394481, -1.0582377, 0.85897416, 0.71786326, 0.7076545, -0.060985327, -0.87769896, -1.0899161, -0.06524671, 0.21581037, -0.40399814, 1.3737159, -0.4202219, -0.18844694, -0.5287598, -0.69054854, 0.18973954, -1.109431, -0.665643, 0.86810124, 1.0030762, 1.4953411, 0.2569824, -1.3876565, -0.9693943, 0.4033383, -0.29836822, 0.16944554, -0.19760334, 1.719698, -0.40945816, 0.3296421, 0.34458864, 1.155594, 1.011761, 0.74752235, -1.0539376, 0.81902856, -0.088945724, 0.38640976, 0.39614975, 0.38105163, -0.9986081, 1.8914497, 0.21451628, -0.08071758, -0.9344926, -0.638808, 1.7585062, 0.01931651, -0.29760137, -0.2640002, -0.14828435, -0.20925501, 1.1644366, -0.32422093, 0.51853573, 0.07865758, 0.60160637, 0.47762248, -0.4061273, -0.35371456, 1.6490239, 0.73574704, -0.9489245, -0.7913597, 0.65340966, 0.35899815, -0.047164954, -0.5332484, -1.3547021, -1.26282, 0.27257475, 0.4286737, 0.2644863, -0.7745581, 0.21653807, -0.2247993, -0.9493463, -0.5836723, 0.52394235, -0.24822555, -0.4213536, -0.80233055, -0.7217113, 0.09229692, 0.13943034, -1.1102285, 0.67371875, 0.12782623, -0.25133812, 0.6497734, 1.3422159, -0.5130991, -0.6515192, -0.70422554, 0.075047195, 0.5081067, 0.65377814, 0.38069543, 0.92894644, 0.42969608, 0.49592248, 0.78385663, 0.14221552, 1.2419767, 0.2971459, 0.50362414, 0.6882868, 0.05406077, -0.18238536, -0.43878293, 1.0658919, 0.21544151, -0.44761363, 0.58880836, -0.95444083, 1.964813, -1.1304772, 0.11464879, -1.3861316, 1.1443179, -0.2656004, 0.36619312, 1.3574054, 0.3002953, -0.52175736, -0.40304264, 0.12032304, -0.046951786, 0.31251994, 0.15777113, 0.05849751, -0.59872293, -0.33397892, -0.6469985, 1.2682323, 1.191048, 0.7295769, 0.45611992, -0.08655806, 0.6216444, 0.5845946, -0.48175794, 0.33236253, 0.13978082, -0.92783093, 1.023435, 0.084055744, 0.11348857, -1.2690697, 1.6041975, -0.12813371, -1.0269929, 0.24939248, -1.272072, 0.12737596, -0.7466035, -0.33500537, 0.2060899, -0.22070761, 1.1950874, -0.30078128, 1.1245154, -0.68544126, -0.09507641, 0.24161565, 1.2158469, -1.0133283, -0.099014245, -0.23311387, -1.2882236, -0.86294657, -0.065702006, -1.5296386, -1.1601006, 0.85721934, 0.3384292, 0.8207317, 0.6236604, 1.1638126, -1.7597797, 0.9378231, 0.21062474, -0.24715583, 0.15357363, 0.7678871, -0.63916945, 0.91885155, 0.18056166, 0.9981235, 0.43932053, 0.9808946, -0.84713525, -1.5895237, -0.14408417, 0.487164, -0.82166266, -0.9124473, -1.1881832, 0.8773857, -1.523799, 0.011868183, 0.95785767, -0.38324893, 0.5184932, -1.0828439, 1.8232999, 0.64405286, -0.55942297, -0.25278056, -0.6656361, 0.07791329, -0.47010398, -0.18716249, 0.6067876, 0.45054254, 0.9510176, -0.06091961, 1.6271837, -0.8581037, -0.949073, 0.014929295, 0.99872994, -0.16249233, -0.7499363, 0.046263017, 0.36411098, 0.29681662, 0.8912034, 0.09468816, -1.1019222, 0.31003067, 0.52036345, 0.59832954, -0.90549743, 0.041481264, 0.50445956, -0.07126953, 0.71694326, 1.2064095, 0.75033945, 0.35338375, 0.19792147, 0.4769883, 0.11720873, 1.5814134, 0.72728854, 1.0159338, -0.072067596, -1.176893, 0.71620417, -0.052375704, 0.7544108, 0.072876215, -0.33411342, -0.35607284, 1.461962, -0.24249646, -0.58780545, 0.9673004, -0.12587, -0.3546834, -1.1994843, -0.5404147, 1.06997, 1.9849299, -0.085531294, -0.05075337, 1.395451, -0.7616445, -0.4205298, -0.4778539, 0.9446511, 0.78825617, 0.93006784, -0.5253528, 0.035713013, -0.80912167, 0.6464114, 0.6647503, -0.7857557, -0.51674825, -1.1067985, 0.6591617, -0.19498006, 1.243342, 0.19363728, -0.8628261, -0.79394054, -1.3814753, 0.0047101905, 0.39828086, -0.106783025]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTjZkSXEeoMB"
   },
   "source": [
    "## 3. Train a classifier using the training set\n",
    "Now that we have the embedding we can train our classifier. We'll use an SVM from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1FGyYoHSCK03",
    "outputId": "d9e09ecb-e569-47a3-8c66-41b076ea5d42"
   },
   "source": [
    "# import support vector machine code\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# initialize the support vector machine, with class_weight='balanced' because \n",
    "# our training set has roughly an equal amount of positive and negative \n",
    "# sentiment sentences\n",
    "svm_classifier = make_pipeline(StandardScaler(), SVC(class_weight='balanced')) \n",
    "\n",
    "# fit the support vector machine\n",
    "svm_classifier.fit(embeddings_train, labels_train)\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('svc',\n",
       "                 SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                     class_weight='balanced', coef0=0.0,\n",
       "                     decision_function_shape='ovr', degree=3, gamma='scale',\n",
       "                     kernel='rbf', max_iter=-1, probability=False,\n",
       "                     random_state=None, shrinking=True, tol=0.001,\n",
       "                     verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VuAjDXjzfWJ7"
   },
   "source": [
    "## 4. Evaluate the performance of the classifier on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NrHAN510fWlm",
    "outputId": "3036bf44-9b71-4698-859a-1f55f0ecc282"
   },
   "source": [
    "# get the score from the test set, and print it out to screen!\n",
    "score = svm_classifier.score(embeddings_test, labels_test)\n",
    "print(f\"Validation accuracy on baseline-shrimp is {100*score}%!\")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation accuracy on baseline-shrimp is 70.0%!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WnfBgA-OkKL"
   },
   "source": [
    "Let's try increasing the size of the model, and using baseline-otter instead to see if we can improve our score."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CSMqRRwT9mrh",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5f6fc80e-cb2d-44f9-8578-7653fdce0ef9"
   },
   "source": [
    "\n",
    "# embed sentences from both train and test set on baseline-otter\n",
    "embeddings_train = co.embed(model='baseline-otter', texts=sentences_train).embeddings\n",
    "embeddings_test = co.embed(model='baseline-otter', texts=sentences_test).embeddings\n",
    "\n",
    "# run the same process as before\n",
    "svm_classifier = make_pipeline(StandardScaler(), SVC(class_weight='balanced')) \n",
    "svm_classifier.fit(embeddings_train, labels_train)\n",
    "score = svm_classifier.score(embeddings_test, labels_test)\n",
    "print(f\"Validation accuracy on baseline-otter is {100*score}%!\")\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation accuracy on baseline-otter is 81.0%!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mqm64NiSgcAt"
   },
   "source": [
    "With a bigger model, we can further improve the accuracy score! This trend typically holds: bigger models tend to create\n",
    "more semantically rich embeddings, that can be used to solve a wider variety of downstream tasks. \n",
    "\n",
    "This was a small scale example, meant as a proof of concept, and designed to illustrate how you can build a custom\n",
    "classifier quickly using a small amount of labelled data and Cohere's embeddings. "
   ]
  }
 ]
}