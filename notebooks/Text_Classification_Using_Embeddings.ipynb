{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4B-KoWi1HDP"
   },
   "source": [
    "# Text Classification Using Embeddings\n",
    "This notebook shows how to build a classifiers using Cohere's embeddings.\n",
    "<img src=\"https://github.com/cohere-ai/notebooks/raw/main/notebooks/images/simple-classifier-embeddings.png\"\n",
    "style=\"width:100%; max-width:600px\"\n",
    "alt=\"first we embed the text in the dataset, then we use that to train a classifier\"/>\n",
    "\n",
    "The example classification task here will be sentiment analysis of film reviews. We'll train a simple classifier to detect whether a film review is negative (class 0) or positive (class 1).\n",
    "\n",
    "We'll go through the following steps:\n",
    "\n",
    "1. Get the dataset\n",
    "2. Get the embeddings of the reviews (for both the training set and the test set).\n",
    "3. Train a classifier using the training set\n",
    "4. Evaluate the performance of the classifier on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XdM6oEyo9oUp"
   },
   "outputs": [],
   "source": [
    "# Let's first install Cohere's python SDK\n",
    "!pip install cohere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0DIiCJoe_-_"
   },
   "source": [
    "## 1. Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "bAVd49D6BjGK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cohere\n",
    "from tqdm import tqdm\n",
    "# Get the SST2 training and test sets\n",
    "df_train = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)\n",
    "df_test = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/test.tsv', delimiter='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BYhG9GO3B_Gd",
    "outputId": "e16f74d7-f6b1-44a6-db0b-49f21a3862e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review #1 text: a stirring , funny and finally transporting re imagining of beauty and the beast and 1930s horror films\n",
      "Review #1 class: 1\n",
      "Review #2 text: apparently reassembled from the cutting room floor of any given daytime soap\n",
      "Review #2 class: 0\n"
     ]
    }
   ],
   "source": [
    "# Let's glance at the dataset\n",
    "df_train.head()\n",
    "print(f\"Review #1 text: {df_train.iloc[0, 0]}\")\n",
    "print(f\"Review #1 class: {df_train.iloc[0, 1]}\")\n",
    "print(f\"Review #2 text: {df_train.iloc[1, 0]}\")\n",
    "print(f\"Review #2 class: {df_train.iloc[1, 1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KIMt6G7dlGC"
   },
   "source": [
    "We'll only use a subset of the training and testing datasets in this example. We'll only use 100 examples since this is a toy example. You'll want to increase the number to get better performance and evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "z_JwX-OQPN_c"
   },
   "outputs": [],
   "source": [
    "n_train_samples = 300 # Increase for better performance (e.g. 500)\n",
    "n_test_samples = 100 # increase for better evaluation (e.g. 500)\n",
    "\n",
    "# Sample from the dataset\n",
    "train = df_train.sample(n_train_samples)\n",
    "test = df_test.sample(n_test_samples)\n",
    "\n",
    "sentences_train = list(train.iloc[:,0].values)\n",
    "sentences_test = list(test.iloc[:,0].values)\n",
    "\n",
    "labels_train  = list(train.iloc[:,1].values)\n",
    "labels_test  = list(test.iloc[:,1].values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aymSE9YFEymy"
   },
   "source": [
    "## 2. Get the embeddings of the reviews\n",
    "We're now ready to retrieve the embeddings from the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "qqfWFS1RDE54"
   },
   "outputs": [],
   "source": [
    "# ADD YOUR API KEY HERE\n",
    "api_key = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Embedding code (Run this cell to execute required code) {display-mode: \"form\"}\n",
    "\n",
    "# Create and retrieve a Cohere API key from os.cohere.ai\n",
    "co = cohere.Client(api_key)\n",
    "\n",
    "\n",
    "# Define a Cohere batch embedding object used to batch embed text\n",
    "class cohereBatchEmbedder():\n",
    "    def __init__(self, model, client, batch_size=5):\n",
    "        self.model = model\n",
    "        self.client = client\n",
    "        self.batch_size = batch_size\n",
    "        self.embeddings = []\n",
    "\n",
    "    def batch_embed(self, examples):\n",
    "        self.embeddings = []\n",
    "        for i in tqdm(range(0,len(examples),self.batch_size)):\n",
    "            batch = examples[i:i+self.batch_size]\n",
    "            emb = self.client.embed(texts=batch,\n",
    "                                    model=self.model,\n",
    "                                    truncate=\"LEFT\").embeddings\n",
    "            self.embeddings += emb\n",
    "        return self.embeddings\n",
    "\n",
    "embedder = cohereBatchEmbedder('small',co,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:25<00:00,  2.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:08<00:00,  2.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# embed sentences from both train and test set on small-20211115\n",
    "\n",
    "embeddings_train = embedder.batch_embed(list(sentences_train))\n",
    "embeddings_test = embedder.batch_embed(list(sentences_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhg6HkuXeFF_"
   },
   "source": [
    "We now have two sets of embeddings, `embeddings_train` contains the embeddings of the training  sentences while `embeddings_test` contains the embeddings of the testing sentences.\n",
    "\n",
    "Curious what an embedding looks like? we can print it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AFWgw-l7eXRG",
    "outputId": "f958e3ff-f6b0-457b-d0e9-9acad20a7e4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review text: and it 's a lousy one at that\n",
      "Embedding vector: [1.8336831, 1.5390223, 0.92042065, 0.23460366, 2.8419993, -0.65512013, 2.6017864, -3.0309973, 1.8228053, -0.57108295]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Review text: {sentences_train[0]}\")\n",
    "print(f\"Embedding vector: {embeddings_train[0][:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTjZkSXEeoMB"
   },
   "source": [
    "## 3. Train a classifier using the training set\n",
    "Now that we have the embedding we can train our classifier. We'll use an SVM from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1FGyYoHSCK03",
    "outputId": "d9e09ecb-e569-47a3-8c66-41b076ea5d42"
   },
   "outputs": [],
   "source": [
    "# import support vector machine code\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# initialize the support vector machine, with class_weight='balanced' because \n",
    "# our training set has roughly an equal amount of positive and negative \n",
    "# sentiment sentences\n",
    "svm_classifier = make_pipeline(StandardScaler(), SVC(class_weight='balanced')) \n",
    "\n",
    "# fit the support vector machine\n",
    "svm_classifier.fit(embeddings_train, labels_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VuAjDXjzfWJ7"
   },
   "source": [
    "## 4. Evaluate the performance of the classifier on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NrHAN510fWlm",
    "outputId": "3036bf44-9b71-4698-859a-1f55f0ecc282"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy on Small is 86.0%!\n"
     ]
    }
   ],
   "source": [
    "# get the score from the test set, and print it out to screen!\n",
    "score = svm_classifier.score(embeddings_test, labels_test)\n",
    "print(f\"Validation accuracy on Small is {100*score}%!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WnfBgA-OkKL",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This was a small scale example, meant as a proof of concept and designed to illustrate how you can build a custom classifier quickly using a small amount of labelled data and Cohere's embeddings. Increase the number of training examples to achieve better performance on this task."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Text Classification Using Embeddings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
