{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Oaa3eXUIDE9N"
      },
      "source": [
        "This is the notebook companion for the blog post [Generative AI with Cohere: Part 4 - Creating Custom Models](https://txt.cohere.com/generative-ai-part-4/)\n",
        "\n",
        "Note: The examples here use a private model. To run these examples yourself, first create a custom model, which steps are detailed on the blog post. The processed training dataset is available [here](https://github.com/cohere-ai/notebooks/blob/main/notebooks/data/content_rephrasing_train.jsonl).\n",
        "\n",
        "***The dataset was adapted from this original source: Sound Natural: Content Rephrasing in Dialog Systems (Einolghozati et al.) [Link](https://aclanthology.org/2020.emnlp-main.414.pdf)***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6Ja95Na3l9se"
      },
      "outputs": [],
      "source": [
        "!pip install cohere > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "koYBtMcrBu7g"
      },
      "outputs": [],
      "source": [
        "import cohere\n",
        "co = cohere.Client('api_key') # Add your API key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLLs-PmKAPOj"
      },
      "source": [
        "## 1 - Baseline model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3z8AD8Od-_Vs",
        "outputId": "9b1b144b-68c3-4b76-9cb5-94a103ea2248"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Temperature range: [0.0, 0.5, 1.0, 1.5]\n",
            "----------\n",
            "Temperature: 0.0\n",
            "----------\n",
            "Generation #1\n",
            "Text: \n",
            "Hey, Alison. Can you pick me up tonight to go to the concert together?\n",
            "\n",
            "Generation #2\n",
            "Text: \n",
            "Hey, Alison. Can you pick me up tonight to go to the concert together?\n",
            "\n",
            "Generation #3\n",
            "Text: \n",
            "Hey, Alison. Can you pick me up tonight to go to the concert together?\n",
            "\n",
            "----------\n",
            "Temperature: 0.5\n",
            "----------\n",
            "Generation #1\n",
            "Text: \n",
            "Message: Alison, can you pick me up tonight to go to the concert together?\n",
            "\n",
            "Generation #2\n",
            "Text: \n",
            "Hey Alison, can you pick me up tonight to go to the concert together?\n",
            "\n",
            "Generation #3\n",
            "Text: \n",
            "Message: Hi Alison, can you pick me up tonight to go to the concert together?\n",
            "\n",
            "----------\n",
            "Temperature: 1.0\n",
            "----------\n",
            "Generation #1\n",
            "Text: \n",
            "Hey Alison, can you pick me up tonight to go to the concert together?\n",
            "\n",
            "Generation #2\n",
            "Text: \n",
            "Hey, Alison. Can you pick me up tonight to go to the concert together?\n",
            "\n",
            "Generation #3\n",
            "Text: \n",
            "\n",
            "\n",
            "\n",
            "----------\n",
            "Temperature: 1.5\n",
            "----------\n",
            "Generation #1\n",
            "Text: \n",
            "Hey Alison, can you pick me up tonight to go to the concert together?\n",
            "\n",
            "Generation #2\n",
            "Text: \n",
            "\n",
            "\n",
            "\n",
            "Generation #3\n",
            "Text: \n",
            "\"Hey, Alison, can you pick me up tonight to go to the concert together?\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a function to call the endpoint\n",
        "def generate_text(prompt,temperature,num_gens):\n",
        "  response = co.generate(\n",
        "    model='command',\n",
        "    prompt=prompt,\n",
        "    temperature=temperature,\n",
        "    num_generations = num_gens,\n",
        "    stop_sequences=[\"\\n\\n\"])\n",
        "  return response\n",
        "\n",
        "# Define the prompt\n",
        "prompt=\"\"\"Turn the following message to a virtual assistant into the correct action:\n",
        "Send a message to Alison to ask if she can pick me up tonight to go to the concert together\"\"\"\n",
        "\n",
        "# Define the range of temperature values and num_generations\n",
        "temperatures = [x / 10.0 for x in range(0, 20, 5)]\n",
        "num_gens = 3\n",
        "\n",
        "# Iterate generation over the range of temperature values\n",
        "print(f\"Temperature range: {temperatures}\")\n",
        "for temperature in temperatures:\n",
        "  response = generate_text(prompt,temperature,num_gens)\n",
        "  print(\"-\"*10)\n",
        "  print(f'Temperature: {temperature}')\n",
        "  print(\"-\"*10)\n",
        "  for i in range(3):\n",
        "    text = response.generations[i].text\n",
        "    likelihood = response.generations[i].likelihood\n",
        "    print(f'Generation #{i+1}')\n",
        "    print(f'Text: {text}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wOyuhhUq-Rl"
      },
      "source": [
        "# 2 - Custom model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8Ex91fJVeth",
        "outputId": "6e501756-85ea-4531-f7b0-62e7a764fe46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Temperature range: [0.0, 0.5, 1.0, 1.5]\n",
            "----------\n",
            "Temperature: 0.0\n",
            "----------\n",
            "Generation #1\n",
            "Text: can you pick me up tonight to go to the concert together\n",
            "\n",
            "Generation #2\n",
            "Text: can you pick me up tonight to go to the concert together\n",
            "\n",
            "Generation #3\n",
            "Text: can you pick me up tonight to go to the concert together\n",
            "\n",
            "----------\n",
            "Temperature: 0.5\n",
            "----------\n",
            "Generation #1\n",
            "Text: can you pick me up tonight to go to the concert together\n",
            "\n",
            "Generation #2\n",
            "Text: can you pick me up tonight to go to the concert together\n",
            "\n",
            "Generation #3\n",
            "Text: can you pick me up tonight to go to the concert together\n",
            "\n",
            "----------\n",
            "Temperature: 1.0\n",
            "----------\n",
            "Generation #1\n",
            "Text: can you pick me up tonight to go to the concert together\n",
            "\n",
            "Generation #2\n",
            "Text: can you pick me up tonight to go to the concert together\n",
            "\n",
            "Generation #3\n",
            "Text: can you pick me up tonight to go to the concert together\n",
            "\n",
            "----------\n",
            "Temperature: 1.5\n",
            "----------\n",
            "Generation #1\n",
            "Text: can you pick me up tonight to go to the concert together\n",
            "\n",
            "Generation #2\n",
            "Text: can you pick me up tonight to go to the concert together\n",
            "\n",
            "Generation #3\n",
            "Text: can you pick me up tonight to go to the concert together\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a function to call the endpoint\n",
        "def generate_text(prompt,temperature,num_gens):\n",
        "  response = co.generate(\n",
        "    model='26db2994-cf88-4243-898d-31258411c120-ft', # REPLACE WITH YOUR MODEL ID\n",
        "    prompt=prompt,\n",
        "    temperature=temperature,\n",
        "    num_generations = num_gens,\n",
        "    stop_sequences=[\"\\n\\n\"])\n",
        "  return response\n",
        "\n",
        "# Define the prompt\n",
        "prompt=\"\"\"Turn the following message to a virtual assistant into the correct action:\n",
        "Send a message to Alison to ask if she can pick me up tonight to go to the concert together\"\"\"\n",
        "\n",
        "# Define the range of temperature values and num_generations\n",
        "temperatures = [x / 10.0 for x in range(0, 20, 5)]\n",
        "num_gens = 3\n",
        "\n",
        "# Iterate generation over the range of temperature values\n",
        "print(f\"Temperature range: {temperatures}\")\n",
        "for temperature in temperatures:\n",
        "  response = generate_text(prompt,temperature,num_gens)\n",
        "  print(\"-\"*10)\n",
        "  print(f'Temperature: {temperature}')\n",
        "  print(\"-\"*10)\n",
        "  for i in range(3):\n",
        "    text = response.generations[i].text\n",
        "    likelihood = response.generations[i].likelihood\n",
        "    print(f'Generation #{i+1}')\n",
        "    print(f'Text: {text}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vf-MKk4yPz8g"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "58b4c372a03222d7f62c5e816fbbc1b3e33f34bb7e19673be34258cc686e1d67"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
