{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oaa3eXUIDE9N"
      },
      "source": [
        "This is the notebook companion for the blog post [Generative AI with Cohere: Part 4 - Creating Custom Models](txt.cohere.ai/generative-ai-part-4/)\n",
        "\n",
        "Note: The examples here use a private model. To run these examples yourself, first create a custom model, which steps are detailed on the blog post. The processed training dataset is available [here](https://github.com/cohere-ai/notebooks/blob/main/notebooks/data/content_rephrasing_train.txt).\n",
        "\n",
        "***Dataset source: Sound Natural: Content Rephrasing in Dialog Systems (Einolghozati et al.) [Link](https://aclanthology.org/2020.emnlp-main.414.pdf)***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ja95Na3l9se"
      },
      "outputs": [],
      "source": [
        "!pip install cohere > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koYBtMcrBu7g"
      },
      "outputs": [],
      "source": [
        "import cohere\n",
        "co = cohere.Client('your_api_key') # Add your API key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLLs-PmKAPOj"
      },
      "source": [
        "## 1 - Baseline model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK-yGe7SM0k_"
      },
      "source": [
        "## Sample calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3z8AD8Od-_Vs",
        "outputId": "8e8bb762-b36a-4474-ed0c-a2468aa7f3f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Temperature range: [0.0, 0.5, 1.0, 1.5]\n",
            "----------\n",
            "Temperature: 0.0\n",
            "----------\n",
            "Generation #1\n",
            "Text:  can you pick me up tonight to go to the concert together\n",
            "\n",
            "\n",
            "\n",
            "Generation #2\n",
            "Text:  can you pick me up tonight to go to the concert together\n",
            "\n",
            "\n",
            "\n",
            "Generation #3\n",
            "Text:  can you pick me up tonight to go to the concert together\n",
            "\n",
            "\n",
            "\n",
            "----------\n",
            "Temperature: 0.5\n",
            "----------\n",
            "Generation #1\n",
            "Text:  ask Alison if she can pick me up tonight to go to the concert together\n",
            "\n",
            "\n",
            "\n",
            "Generation #2\n",
            "Text:  Can you pick me up tonight to go to the concert together\n",
            "\n",
            "\n",
            "\n",
            "Generation #3\n",
            "Text:  can you pick me up tonight to go to the concert together\n",
            "\n",
            "\n",
            "\n",
            "----------\n",
            "Temperature: 1.0\n",
            "----------\n",
            "Generation #1\n",
            "Text:  send a message to alison to ask if she can pick me up tonight to go to the concert\n",
            "\n",
            "Generation #2\n",
            "Text:  can you pick me up tonight to go to the concert together\n",
            "\n",
            "\n",
            "\n",
            "Generation #3\n",
            "Text:  can you pick me up tonight to go to the concert together\n",
            "\n",
            "\n",
            "\n",
            "----------\n",
            "Temperature: 1.5\n",
            "----------\n",
            "Generation #1\n",
            "Text:  send a message to alison to ask if she can pick me up tonight to go to the concert\n",
            "\n",
            "Generation #2\n",
            "Text:  Send a message to Alison to ask if she can pick me up tonight to go to the concert together\n",
            "\n",
            "Generation #3\n",
            "Text:  can you pick me up tonight to go to the concert together\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a function to call the endpoint\n",
        "def generate_text(prompt,temperature,num_gens):\n",
        "  response = co.generate(\n",
        "    model='base',\n",
        "    prompt=prompt,\n",
        "    temperature=temperature,\n",
        "    num_generations = num_gens,\n",
        "    stop_sequences=[\"\\n\\n\"])\n",
        "  return response\n",
        "\n",
        "# Define the prompt\n",
        "prompt=\"\"\"Request: Ask my aunt if she can go to the JDRF Walk with me October 6th\n",
        "Utterance: can you go to the jdrf walk with me october 6th\n",
        "\n",
        "--\n",
        "Request: Ask Eliza what should I bring to the wedding tomorrow\n",
        "Utterance: what should I bring to the wedding tomorrow\n",
        "\n",
        "--\n",
        "Request: Send message to supervisor that I am sick and will not be in today\n",
        "Utterance: I am sick and will not be in today\n",
        "\n",
        "--\n",
        "Request: Send a message to Alison to ask if she can pick me up tonight to go to the concert together\n",
        "Utterance:\"\"\"\n",
        "\n",
        "# Define the range of temperature values and num_generations\n",
        "temperatures = [x / 10.0 for x in range(0, 20, 5)]\n",
        "num_gens = 3\n",
        "\n",
        "# Iterate generation over the range of temperature values\n",
        "print(f\"Temperature range: {temperatures}\")\n",
        "for temperature in temperatures:\n",
        "  response = generate_text(prompt,temperature,num_gens)\n",
        "  print(\"-\"*10)\n",
        "  print(f'Temperature: {temperature}')\n",
        "  print(\"-\"*10)\n",
        "  for i in range(3):\n",
        "    text = response.generations[i].text\n",
        "    likelihood = response.generations[i].likelihood\n",
        "    print(f'Generation #{i+1}')\n",
        "    print(f'Text: {text}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1OBzWz4Jvf1"
      },
      "source": [
        "## Likelihood"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSa7rbwWJq0w",
        "outputId": "02540d6d-b3d0-40ee-a3d9-1e48592aadab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-2.5899453\n"
          ]
        }
      ],
      "source": [
        "prompt=\"\"\"Request: Send a message to Alison to ask if she can pick me up tonight to go to the concert together\n",
        "Utterance: can you pick me up tonight to go to the concert together\"\"\"\n",
        "\n",
        "response = co.generate(\n",
        "  model='base',\n",
        "  prompt=prompt,\n",
        "  max_tokens=0,\n",
        "  temperature=1,\n",
        "  stop_sequences=[\"\\n\\n\"],\n",
        "  return_likelihoods=\"ALL\")\n",
        "\n",
        "print(response.generations[0].likelihood)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wOyuhhUq-Rl"
      },
      "source": [
        "# 2 - Custom model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZf4vxj9M_4E"
      },
      "source": [
        "## Sample calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8Ex91fJVeth",
        "outputId": "7bfe6088-1021-4b4f-c280-91a63956062a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Temperature range: [0.0, 0.5, 1.0, 1.5]\n",
            "----------\n",
            "Temperature: 0.0\n",
            "----------\n",
            "Generation #1\n",
            "Text:  can you pick me up tonight to go to the concert together\n",
            "\n",
            "\n",
            "\n",
            "Generation #2\n",
            "Text:  can you pick me up tonight to go to the concert together\n",
            "\n",
            "\n",
            "\n",
            "Generation #3\n",
            "Text:  can you pick me up tonight to go to the concert together\n",
            "\n",
            "\n",
            "\n",
            "----------\n",
            "Temperature: 0.5\n",
            "----------\n",
            "Generation #1\n",
            "Text:  can you pick me up tonight to go to the concert together\n",
            "\n",
            "\n",
            "\n",
            "Generation #2\n",
            "Text:  can you pick me up tonight to go to the concert together\n",
            "\n",
            "\n",
            "\n",
            "Generation #3\n",
            "Text:  can you pick me up tonight to go to the concert together\n",
            "\n",
            "\n",
            "\n",
            "----------\n",
            "Temperature: 1.0\n",
            "----------\n",
            "Generation #1\n",
            "Text:  can you pick me up tonight to go to the concert together\n",
            "\n",
            "\n",
            "\n",
            "Generation #2\n",
            "Text:  can you pick me up tonight to go to the concert together\n",
            "\n",
            "\n",
            "\n",
            "Generation #3\n",
            "Text:  can you pick me up tonight to go to the concert together\n",
            "\n",
            "\n",
            "\n",
            "----------\n",
            "Temperature: 1.5\n",
            "----------\n",
            "Generation #1\n",
            "Text:  can you pick me up tonight to go to the concert together\n",
            "\n",
            "\n",
            "\n",
            "Generation #2\n",
            "Text:  can you pick me up tonight to go to the concert together\n",
            "\n",
            "\n",
            "\n",
            "Generation #3\n",
            "Text:  can you pick me up tonight to go to the concert together\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a function to call the endpoint\n",
        "def generate_text(prompt,temperature,num_gens):\n",
        "  response = co.generate(\n",
        "    model='59755b6f-2486-4cdc-a38e-f16a04c55856-ft', # REPLACE WITH YOUR MODEL ID\n",
        "    prompt=prompt,\n",
        "    temperature=temperature,\n",
        "    num_generations = num_gens,\n",
        "    stop_sequences=[\"\\n\\n\"])\n",
        "  return response\n",
        "\n",
        "# Define the prompt\n",
        "prompt=\"\"\"Request: Send a message to Alison to ask if she can pick me up tonight to go to the concert together\n",
        "Utterance:\"\"\"\n",
        "\n",
        "# Define the range of temperature values and num_generations\n",
        "temperatures = [x / 10.0 for x in range(0, 20, 5)]\n",
        "num_gens = 3\n",
        "\n",
        "# Iterate generation over the range of temperature values\n",
        "print(f\"Temperature range: {temperatures}\")\n",
        "for temperature in temperatures:\n",
        "  response = generate_text(prompt,temperature,num_gens)\n",
        "  print(\"-\"*10)\n",
        "  print(f'Temperature: {temperature}')\n",
        "  print(\"-\"*10)\n",
        "  for i in range(3):\n",
        "    text = response.generations[i].text\n",
        "    likelihood = response.generations[i].likelihood\n",
        "    print(f'Generation #{i+1}')\n",
        "    print(f'Text: {text}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXktNOy8NDrk"
      },
      "source": [
        "## Likelihood"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb1TPnQUJPJV",
        "outputId": "6274aae2-b062-4b15-b6af-f6b30cc99d65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-1.3724834\n"
          ]
        }
      ],
      "source": [
        "prompt=\"\"\"Request: Send a message to Alison to ask if she can pick me up tonight to go to the concert together\n",
        "Utterance: can you pick me up tonight to go to the concert together\"\"\"\n",
        "\n",
        "response = co.generate(\n",
        "  model='59755b6f-2486-4cdc-a38e-f16a04c55856-ft', # REPLACE WITH YOUR MODEL ID\n",
        "  prompt=prompt,\n",
        "  max_tokens=0,\n",
        "  temperature=1,\n",
        "  stop_sequences=[\"\\n\\n\"],\n",
        "  return_likelihoods=\"ALL\")\n",
        "print(response.generations[0].likelihood)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "58b4c372a03222d7f62c5e816fbbc1b3e33f34bb7e19673be34258cc686e1d67"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
