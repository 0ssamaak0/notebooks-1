{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Build a RAG-Powered Chatbot with Chat, Embed, and Rerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Read the accompanying [blog post here](https://txt.cohere.com/rag-chatbot).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Feature](images/rag-chatbot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you’ll learn how to build a chatbot that has RAG capabilities, enabling it to connect to external documents, ground its responses on these documents, and produce document citations in its responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a diagram that provides an overview of what we’ll build, followed by a list of the key steps involved.\n",
    "\n",
    "![Overview](images/rag-chatbot-flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup phase:\n",
    "- Step 0: Ingest the documents – get documents, chunk, embed, and index.\n",
    "\n",
    "For each user-chatbot interaction:\n",
    "- Step 1: Get the user message\n",
    "- Step 2: Call the Chat endpoint in query-generation mode\n",
    "- If at least one query is generated\n",
    "    - Step 3: Retrieve and rerank relevant documents\n",
    "    - Step 4: Call the Chat endpoint in document mode to generate a grounded response with citations\n",
    "- If no query is generated\n",
    "    - Step 4: Call the Chat endpoint in normal mode to generate a response\n",
    "\n",
    "Throughout the conversation:\n",
    "- Append the user-chatbot interaction to the conversation thread\n",
    "- Repeat with every interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install cohere hnswlib unstructured -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import hnswlib\n",
    "import json\n",
    "import uuid\n",
    "from typing import List, Dict\n",
    "from unstructured.partition.html import partition_html\n",
    "from unstructured.chunking.title import chunk_by_title\n",
    "\n",
    "# co = cohere.Client(\"COHERE_API_KEY\")\n",
    "import os\n",
    "co = cohere.Client(os.getenv(\"COHERE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Enable text wrapping in Google colab\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "def set_css():\n",
    "  display(HTML('''\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  '''))\n",
    "get_ipython().events.register('pre_run_cell', set_css)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documents component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Documents:\n",
    "    \"\"\"\n",
    "    A class representing a collection of documents.\n",
    "\n",
    "    Parameters:\n",
    "    sources (list): A list of dictionaries representing the sources of the documents. Each dictionary should have 'title' and 'url' keys.\n",
    "\n",
    "    Attributes:\n",
    "    sources (list): A list of dictionaries representing the sources of the documents.\n",
    "    docs (list): A list of dictionaries representing the documents, with 'title', 'content', and 'url' keys.\n",
    "    docs_embs (list): A list of the associated embeddings for the documents.\n",
    "    retrieve_top_k (int): The number of documents to retrieve during search.\n",
    "    rerank_top_k (int): The number of documents to rerank after retrieval.\n",
    "    docs_len (int): The number of documents in the collection.\n",
    "    index (hnswlib.Index): The index used for document retrieval.\n",
    "\n",
    "    Methods:\n",
    "    load(): Loads the data from the sources and partitions the HTML content into chunks.\n",
    "    embed(): Embeds the documents using the Cohere API.\n",
    "    index(): Indexes the documents for efficient retrieval.\n",
    "    retrieve(query): Retrieves documents based on the given query.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sources: List[Dict[str, str]]):\n",
    "        self.sources = sources\n",
    "        self.docs = []\n",
    "        self.docs_embs = []\n",
    "        self.retrieve_top_k = 10\n",
    "        self.rerank_top_k = 3\n",
    "        self.load()\n",
    "        self.embed()\n",
    "        self.index()\n",
    "\n",
    "    def load(self) -> None:\n",
    "        \"\"\"\n",
    "        Loads the documents from the sources and chunks the HTML content.\n",
    "        \"\"\"\n",
    "        print(\"Loading documents...\")\n",
    "\n",
    "        for source in self.sources:\n",
    "            elements = partition_html(url=source[\"url\"])\n",
    "            chunks = chunk_by_title(elements)\n",
    "            for chunk in chunks:\n",
    "                self.docs.append(\n",
    "                    {\n",
    "                        \"title\": source[\"title\"],\n",
    "                        \"text\": str(chunk),\n",
    "                        \"url\": source[\"url\"],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    def embed(self) -> None:\n",
    "        \"\"\"\n",
    "        Embeds the documents using the Cohere API.\n",
    "        \"\"\"\n",
    "        print(\"Embedding documents...\")\n",
    "\n",
    "        batch_size = 90\n",
    "        self.docs_len = len(self.docs)\n",
    "\n",
    "        for i in range(0, self.docs_len, batch_size):\n",
    "            batch = self.docs[i : min(i + batch_size, self.docs_len)]\n",
    "            texts = [item[\"text\"] for item in batch]\n",
    "            docs_embs_batch = co.embed(\n",
    "                texts=texts, model=\"embed-english-v3.0\", input_type=\"search_document\"\n",
    "            ).embeddings\n",
    "            self.docs_embs.extend(docs_embs_batch)\n",
    "\n",
    "    def index(self) -> None:\n",
    "        \"\"\"\n",
    "        Indexes the documents for efficient retrieval.\n",
    "        \"\"\"\n",
    "        print(\"Indexing documents...\")\n",
    "\n",
    "        self.idx = hnswlib.Index(space=\"ip\", dim=1024)\n",
    "        self.idx.init_index(max_elements=self.docs_len, ef_construction=512, M=64)\n",
    "        self.idx.add_items(self.docs_embs, list(range(len(self.docs_embs))))\n",
    "\n",
    "        print(f\"Indexing complete with {self.idx.get_current_count()} documents.\")\n",
    "\n",
    "    def retrieve(self, query: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Retrieves documents based on the given query.\n",
    "\n",
    "        Parameters:\n",
    "        query (str): The query to retrieve documents for.\n",
    "\n",
    "        Returns:\n",
    "        List[Dict[str, str]]: A list of dictionaries representing the retrieved documents, with 'title', 'text', and 'url' keys.\n",
    "        \"\"\"\n",
    "        docs_retrieved = []\n",
    "        query_emb = co.embed(\n",
    "            texts=[query], model=\"embed-english-v3.0\", input_type=\"search_query\"\n",
    "        ).embeddings\n",
    "\n",
    "        doc_ids = self.idx.knn_query(query_emb, k=self.retrieve_top_k)[0][0]\n",
    "\n",
    "        docs_to_rerank = []\n",
    "        for doc_id in doc_ids:\n",
    "            docs_to_rerank.append(self.docs[doc_id][\"text\"])\n",
    "\n",
    "        rerank_results = co.rerank(\n",
    "            query=query,\n",
    "            documents=docs_to_rerank,\n",
    "            top_n=self.rerank_top_k,\n",
    "            model=\"rerank-english-v2.0\",\n",
    "        )\n",
    "\n",
    "        doc_ids_reranked = []\n",
    "        for result in rerank_results:\n",
    "            doc_ids_reranked.append(doc_ids[result.index])\n",
    "\n",
    "        for doc_id in doc_ids_reranked:\n",
    "            docs_retrieved.append(\n",
    "                {\n",
    "                    \"title\": self.docs[doc_id][\"title\"],\n",
    "                    \"text\": self.docs[doc_id][\"text\"],\n",
    "                    \"url\": self.docs[doc_id][\"url\"],\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return docs_retrieved"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbot component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Chatbot:\n",
    "    \"\"\"\n",
    "    A class representing a chatbot.\n",
    "\n",
    "    Parameters:\n",
    "    docs (Documents): An instance of the Documents class representing the collection of documents.\n",
    "\n",
    "    Attributes:\n",
    "    conversation_id (str): The unique ID for the conversation.\n",
    "    docs (Documents): An instance of the Documents class representing the collection of documents.\n",
    "\n",
    "    Methods:\n",
    "    generate_response(message): Generates a response to the user's message.\n",
    "    retrieve_docs(response): Retrieves documents based on the search queries in the response.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, docs: Documents):\n",
    "        self.docs = docs\n",
    "        self.conversation_id = str(uuid.uuid4())\n",
    "\n",
    "    def generate_response(self, message: str):\n",
    "        \"\"\"\n",
    "        Generates a response to the user's message.\n",
    "\n",
    "        Parameters:\n",
    "        message (str): The user's message.\n",
    "\n",
    "        Yields:\n",
    "        Event: A response event generated by the chatbot.\n",
    "\n",
    "        Returns:\n",
    "        List[Dict[str, str]]: A list of dictionaries representing the retrieved documents.\n",
    "\n",
    "        \"\"\"\n",
    "        # Generate search queries (if any)\n",
    "        response = co.chat(message=message, search_queries_only=True)\n",
    "\n",
    "        # If there are search queries, retrieve documents and respond\n",
    "        preamble_override = \"You only answer questions using on the documents you have provided with\"\n",
    "        \n",
    "        if response.search_queries:\n",
    "            print(\"Retrieving information...\")\n",
    "\n",
    "            documents = self.retrieve_docs(response)\n",
    "\n",
    "            response = co.chat(\n",
    "                message=message,\n",
    "                preamble_override = preamble_override,\n",
    "                documents=documents,\n",
    "                conversation_id=self.conversation_id,\n",
    "                stream=True,\n",
    "            )\n",
    "            for event in response:\n",
    "                yield event\n",
    "            yield response\n",
    "\n",
    "        # If there is no search query, directly respond\n",
    "        else:\n",
    "            response = co.chat(\n",
    "                message=message,\n",
    "                preamble_override = preamble_override,\n",
    "                conversation_id=self.conversation_id, \n",
    "                stream=True\n",
    "            )\n",
    "            for event in response:\n",
    "                yield event\n",
    "\n",
    "    def retrieve_docs(self, response) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Retrieves documents based on the search queries in the response.\n",
    "\n",
    "        Parameters:\n",
    "        response: The response object containing search queries.\n",
    "\n",
    "        Returns:\n",
    "        List[Dict[str, str]]: A list of dictionaries representing the retrieved documents.\n",
    "\n",
    "        \"\"\"\n",
    "        # Get the query(s)\n",
    "        queries = []\n",
    "        for search_query in response.search_queries:\n",
    "            queries.append(search_query[\"text\"])\n",
    "\n",
    "        # Retrieve documents for each query\n",
    "        retrieved_docs = []\n",
    "        for query in queries:\n",
    "            retrieved_docs.extend(self.docs.retrieve(query))\n",
    "\n",
    "        return retrieved_docs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### App component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class App:\n",
    "    def __init__(self, chatbot: Chatbot):\n",
    "        \"\"\"\n",
    "        Initializes an instance of the App class.\n",
    "\n",
    "        Parameters:\n",
    "        chatbot (Chatbot): An instance of the Chatbot class.\n",
    "\n",
    "        \"\"\"\n",
    "        self.chatbot = chatbot\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Runs the chatbot application.\n",
    "\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            # Get the user message\n",
    "            message = input(\"User: \")\n",
    "\n",
    "            # Typing \"quit\" ends the conversation\n",
    "            if message.lower() == \"quit\":\n",
    "                print(\"Ending chat.\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"User: {message}\")\n",
    "\n",
    "            # Get the chatbot response\n",
    "            response = self.chatbot.generate_response(message)\n",
    "\n",
    "            # Print the chatbot response\n",
    "            print(\"Chatbot:\")\n",
    "            \n",
    "            citations_flag = False\n",
    "            \n",
    "            for event in response:\n",
    "                stream_type = type(event).__name__\n",
    "                    # Text\n",
    "                if stream_type == \"StreamTextGeneration\":\n",
    "                    print(event.text, end=\"\")\n",
    "\n",
    "                # Citations\n",
    "                if stream_type == \"StreamCitationGeneration\":\n",
    "                    if not citations_flag:\n",
    "                        print(\"\\n\\nCITATIONS:\")\n",
    "                        citations_flag = True\n",
    "                    print(event.citations[0])\n",
    "                    \n",
    "                if citations_flag:\n",
    "                    if stream_type == \"StreamingChat\":\n",
    "                        print(\"\\n\\nDOCUMENTS:\")\n",
    "                        documents = [{'id': doc['id'], 'text': doc['text'][:50] + '...', 'title': doc['title'], 'url': doc['url']} \n",
    "                                     for doc in event.documents]\n",
    "                        for doc in documents:\n",
    "                            print(doc)\n",
    "\n",
    "            print(f\"\\n{'-'*100}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the sources for the documents\n",
    "# As an example, we'll use LLM University's Module 1: What are Large Language Models?\n",
    "# https://docs.cohere.com/docs/intro-large-language-models\n",
    "\n",
    "sources = [\n",
    "    {\n",
    "        \"title\": \"Text Embeddings\", \n",
    "        \"url\": \"https://docs.cohere.com/docs/text-embeddings\"},\n",
    "    {\n",
    "        \"title\": \"Similarity Between Words and Sentences\", \n",
    "        \"url\": \"https://docs.cohere.com/docs/similarity-between-words-and-sentences\"},\n",
    "    {\n",
    "        \"title\": \"The Attention Mechanism\", \n",
    "        \"url\": \"https://docs.cohere.com/docs/the-attention-mechanism\"},\n",
    "    {\n",
    "        \"title\": \"Transformer Models\", \n",
    "        \"url\": \"https://docs.cohere.com/docs/transformer-models\"}   \n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents...\n",
      "Embedding documents...\n",
      "Indexing documents...\n",
      "Indexing complete with 136 documents.\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the Documents class with the given sources\n",
    "documents = Documents(sources)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hello\n",
      "Chatbot:\n",
      "Hello there, how can I assist you today?\n",
      "\n",
      "Please provide some further information or give me a specific question, and I'll do my best to help you out!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "User: What is the difference between word and sentence embeddings\n",
      "Chatbot:\n",
      "Retrieving information...\n",
      "Word embeddings and sentence embeddings are the fundamental components of LLMs and convert language (words) into computer speak (numbers) in a way that preserves the relationships between words, semantics, and linguistic nuances into numerical equations. \n",
      "\n",
      "Word embeddings associate words with lists of numbers (vectors) in a way that groups similar words together. Sentence embeddings do the same thing but for sentences.\n",
      "\n",
      "CITATIONS:\n",
      "{'start': 0, 'end': 15, 'text': 'Word embeddings', 'document_ids': ['doc_0', 'doc_1', 'doc_2']}\n",
      "{'start': 20, 'end': 39, 'text': 'sentence embeddings', 'document_ids': ['doc_0', 'doc_1', 'doc_2']}\n",
      "{'start': 48, 'end': 78, 'text': 'fundamental components of LLMs', 'document_ids': ['doc_2']}\n",
      "{'start': 83, 'end': 137, 'text': 'convert language (words) into computer speak (numbers)', 'document_ids': ['doc_2']}\n",
      "{'start': 152, 'end': 228, 'text': 'preserves the relationships between words, semantics, and linguistic nuances', 'document_ids': ['doc_2']}\n",
      "{'start': 234, 'end': 254, 'text': 'numerical equations.', 'document_ids': ['doc_2']}\n",
      "{'start': 257, 'end': 365, 'text': 'Word embeddings associate words with lists of numbers (vectors) in a way that groups similar words together.', 'document_ids': ['doc_0', 'doc_1']}\n",
      "{'start': 366, 'end': 422, 'text': 'Sentence embeddings do the same thing but for sentences.', 'document_ids': ['doc_0', 'doc_1']}\n",
      "\n",
      "\n",
      "DOCUMENTS:\n",
      "{'id': 'doc_0', 'text': 'In the previous chapters, you learned about word a...', 'title': 'The Attention Mechanism', 'url': 'https://docs.cohere.com/docs/the-attention-mechanism'}\n",
      "{'id': 'doc_1', 'text': 'This is where sentence embeddings come into play. ...', 'title': 'Text Embeddings', 'url': 'https://docs.cohere.com/docs/text-embeddings'}\n",
      "{'id': 'doc_2', 'text': 'Conclusion\\n\\nWord and sentence embeddings are the b...', 'title': 'Text Embeddings', 'url': 'https://docs.cohere.com/docs/text-embeddings'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ending chat.\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the Chatbot class with the Documents instance\n",
    "chatbot = Chatbot(documents)\n",
    "\n",
    "# Create an instance of the App class with the Chatbot instance\n",
    "app = App(chatbot)\n",
    "\n",
    "# Run the chatbot\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
