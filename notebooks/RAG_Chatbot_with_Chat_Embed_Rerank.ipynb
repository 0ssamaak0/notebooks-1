{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Build a RAG-Powered Chatbot with Chat, Embed, and Rerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Read the accompanying [blog post here](https://txt.cohere.com/rag-chatbot).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Feature](images/rag-chatbot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you’ll learn how to build a chatbot that has RAG capabilities, enabling it to connect to external documents, ground its responses on these documents, and produce document citations in its responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a diagram that provides an overview of what we’ll build, followed by a list of the key steps involved.\n",
    "\n",
    "![Overview](images/rag-chatbot-flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup phase:\n",
    "- Step 0: Ingest the documents – get documents, chunk, embed, and index.\n",
    "\n",
    "For each user-chatbot interaction:\n",
    "- Step 1: Get the user message\n",
    "- Step 2: Call the Chat endpoint in query-generation mode\n",
    "- If at least one query is generated\n",
    "    - Step 3: Retrieve and rerank relevant documents\n",
    "    - Step 4: Call the Chat endpoint in document mode to generate a grounded response with citations\n",
    "- If no query is generated\n",
    "    - Step 4: Call the Chat endpoint in normal mode to generate a response\n",
    "\n",
    "Throughout the conversation:\n",
    "- Append the user-chatbot interaction to the conversation thread\n",
    "- Repeat with every interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: upgrade to \"cohere>5\"",
"! pip install \"cohere<5\" hnswlib unstructured -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import hnswlib\n",
    "import json\n",
    "import uuid\n",
    "from typing import List, Dict\n",
    "from unstructured.partition.html import partition_html\n",
    "from unstructured.chunking.title import chunk_by_title\n",
    "\n",
    "co = cohere.Client(\"COHERE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Enable text wrapping in Google colab\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "def set_css():\n",
    "  display(HTML('''\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  '''))\n",
    "get_ipython().events.register('pre_run_cell', set_css)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datastore component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datastore:\n",
    "    \"\"\"\n",
    "    A class representing a collection of documents.\n",
    "\n",
    "    Parameters:\n",
    "    sources (list): A list of dictionaries representing the sources of the documents. Each dictionary should have 'title' and 'url' keys.\n",
    "\n",
    "    Attributes:\n",
    "    sources (list): A list of dictionaries representing the sources of the documents.\n",
    "    docs (list): A list of dictionaries representing the documents, with 'title', 'content', and 'url' keys.\n",
    "    docs_embs (list): A list of the associated embeddings for the documents.\n",
    "    docs_len (int): The number of documents in the collection.\n",
    "    index (hnswlib.Index): The index used for document retrieval.\n",
    "\n",
    "    Methods:\n",
    "    load_and_chunk(): Loads the data from the sources and partitions the HTML content into chunks.\n",
    "    embed(): Embeds the documents using the Cohere API.\n",
    "    index(): Indexes the documents for efficient retrieval.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, raw_documents: List[Dict[str, str]]):\n",
    "        self.raw_documents = raw_documents  # raw documents\n",
    "        self.chunks = []            # chunked version of documents\n",
    "        self.chunks_embs = []       # embeddings of chunked documents\n",
    "        self.retrieve_top_k = 10\n",
    "        self.rerank_top_k = 3\n",
    "        self.load_and_chunk()  # load raw documents and break into chunks\n",
    "        self.embed() # generate embeddings for each chunk\n",
    "        self.index() # store embeddings in an index\n",
    "\n",
    "\n",
    "    def load_and_chunk(self) -> None:\n",
    "        \"\"\"\n",
    "        Loads the text from the sources and chunks the HTML content.\n",
    "        \"\"\"\n",
    "        print(\"Loading documents...\")\n",
    "\n",
    "        for source in self.raw_documents:\n",
    "            elements = partition_html(url=source[\"url\"])\n",
    "            chunks = chunk_by_title(elements)\n",
    "            for chunk in chunks:\n",
    "                self.chunks.append(\n",
    "                    {\n",
    "                        \"title\": source[\"title\"],\n",
    "                        \"text\": str(chunk),\n",
    "                        \"url\": source[\"url\"],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    def embed(self) -> None:\n",
    "        \"\"\"\n",
    "        Embeds the document chunks using the Cohere API.\n",
    "        \"\"\"\n",
    "        print(\"Embedding document chunks...\")\n",
    "\n",
    "        batch_size = 90\n",
    "        self.chunks_len = len(self.chunks)\n",
    "\n",
    "        for i in range(0, self.chunks_len, batch_size):\n",
    "            batch = self.chunks[i : min(i + batch_size, self.chunks_len)]\n",
    "            texts = [item[\"text\"] for item in batch]\n",
    "            chunks_embs_batch = co.embed(\n",
    "                texts=texts, model=\"embed-english-v3.0\", input_type=\"search_document\"\n",
    "            ).embeddings\n",
    "            self.chunks_embs.extend(chunks_embs_batch)\n",
    "\n",
    "    def index(self) -> None:\n",
    "        \"\"\"\n",
    "        Indexes the document chunks for efficient retrieval.\n",
    "        \"\"\"\n",
    "        print(\"Indexing documents...\")\n",
    "\n",
    "        self.idx = hnswlib.Index(space=\"ip\", dim=1024)\n",
    "        self.idx.init_index(max_elements=self.chunks_len, ef_construction=512, M=64)\n",
    "        self.idx.add_items(self.chunks_embs, list(range(len(self.chunks_embs))))\n",
    "\n",
    "        print(f\"Indexing complete with {self.idx.get_current_count()} documents.\")\n",
    "\n",
    "        return self.idx\n",
    "\n",
    "    def search_and_rerank(self, query: str) -> List[Dict[str, str]]:\n",
    "        # SEARCH\n",
    "        query_emb = co.embed(\n",
    "                  texts=[query], model=\"embed-english-v3.0\", input_type=\"search_query\"\n",
    "              ).embeddings\n",
    "\n",
    "        chunk_ids = self.idx.knn_query(query_emb, k=self.retrieve_top_k)[0][0]\n",
    "\n",
    "        # RERANK\n",
    "        chunks_to_rerank = [self.chunks[chunk_id][\"text\"] for chunk_id in chunk_ids]\n",
    "\n",
    "        rerank_results = co.rerank(\n",
    "            query=query,\n",
    "            documents=chunks_to_rerank,\n",
    "            top_n=self.rerank_top_k,\n",
    "            model=\"rerank-english-v2.0\",\n",
    "        )\n",
    "\n",
    "        chunk_ids_reranked = [chunk_ids[result.index] for result in rerank_results]\n",
    "\n",
    "        chunks_retrieved = []\n",
    "        for chunk_id in chunk_ids_reranked:\n",
    "            chunks_retrieved.append(\n",
    "                {\n",
    "                \"title\": self.chunks[chunk_id][\"title\"],\n",
    "                \"text\": self.chunks[chunk_id][\"text\"],\n",
    "                \"url\": self.chunks[chunk_id][\"url\"],\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return chunks_retrieved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and process documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents...\n",
      "Embedding document chunks...\n",
      "Indexing documents...\n",
      "Indexing complete with 136 documents.\n"
     ]
    }
   ],
   "source": [
    "# Define the sources for the documents\n",
    "# As an example, we'll use LLM University's Module 1: What are Large Language Models?\n",
    "# https://docs.cohere.com/docs/intro-large-language-models\n",
    "\n",
    "sources = [\n",
    "    {\n",
    "        \"title\": \"Text Embeddings\", \n",
    "        \"url\": \"https://docs.cohere.com/docs/text-embeddings\"},\n",
    "    {\n",
    "        \"title\": \"Similarity Between Words and Sentences\", \n",
    "        \"url\": \"https://docs.cohere.com/docs/similarity-between-words-and-sentences\"},\n",
    "    {\n",
    "        \"title\": \"The Attention Mechanism\", \n",
    "        \"url\": \"https://docs.cohere.com/docs/the-attention-mechanism\"},\n",
    "    {\n",
    "        \"title\": \"Transformer Models\", \n",
    "        \"url\": \"https://docs.cohere.com/docs/transformer-models\"}   \n",
    "]\n",
    "\n",
    "# Create an instance of the Datastore class with the given sources\n",
    "datastore = Datastore(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Similarity Between Words and Sentences',\n",
       "  'text': 'In the previous chapter, I explained the concept of word embeddings. In a nutshell, a word embedding is an assignment of a list of numbers (vector) to every word, in a way that semantic properties of the word translate into mathematical properties of the numbers. What do we mean by this? For example, two similar words will have similar vectors, and two different words will have different vectors. But most importantly, each entry in the vector corresponding to a word keeps track of some property ',\n",
       "  'url': 'https://docs.cohere.com/docs/similarity-between-words-and-sentences'},\n",
       " {'title': 'The Attention Mechanism',\n",
       "  'text': 'In the previous chapters, you learned about word and sentence embeddings and similarity between words and sentences. In short, a word embedding is a way to associate words with lists of numbers (vectors) in such a way that similar words are associated with numbers that are close by, and dissimilar words with numbers that are far away from each other. A sentence embedding does the same thing, but associating a vector to every sentence. Similarity is a way to measure how similar two words (or sent',\n",
       "  'url': 'https://docs.cohere.com/docs/the-attention-mechanism'},\n",
       " {'title': 'Text Embeddings',\n",
       "  'text': 'Text Embeddings\\n\\nWord and sentence embeddings are the bread and butter of language models. This chapter shows a very simple introduction to what they are.',\n",
       "  'url': 'https://docs.cohere.com/docs/text-embeddings'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test retrieving documents from the datastore\n",
    "datastore.search_and_rerank(\"word embeddings\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbot component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Chatbot:\n",
    "    def __init__(self, datastore: Datastore):\n",
    "        \"\"\"\n",
    "        Initializes an instance of the Chatbot class.\n",
    "\n",
    "        Parameters:\n",
    "        storage (Storage): An instance of the Storage class.\n",
    "\n",
    "        \"\"\"\n",
    "        self.datastore = datastore\n",
    "        self.conversation_id = str(uuid.uuid4())\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Runs the chatbot application.\n",
    "\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            # Get the user message\n",
    "            message = input(\"User: \")\n",
    "\n",
    "            # Typing \"quit\" ends the conversation\n",
    "            if message.lower() == \"quit\":\n",
    "                print(\"Ending chat.\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"User: {message}\")\n",
    "\n",
    "            # Generate search queries, if any\n",
    "            response_queries = co.chat(message=message, search_queries_only=True)\n",
    "\n",
    "            if response_queries.search_queries:\n",
    "                print(\"Retrieving information...\", end=\"\")\n",
    "\n",
    "                # Get the query(s)\n",
    "                queries = []\n",
    "                for search_query in response_queries.search_queries:\n",
    "                    queries.append(search_query[\"text\"])\n",
    "\n",
    "                # Retrieve documents for each query\n",
    "                chunks = []\n",
    "                for query in queries:\n",
    "                    chunks.extend(self.datastore.search_and_rerank(query))\n",
    "            \n",
    "                response = co.chat(\n",
    "                    message=message,\n",
    "                    documents=chunks,\n",
    "                    conversation_id=self.conversation_id,\n",
    "                    stream=True,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                response = co.chat(\n",
    "                    message=message,\n",
    "                    conversation_id=self.conversation_id,\n",
    "                    stream=True,\n",
    "                )\n",
    "\n",
    "            # Print the chatbot response\n",
    "            print(\"\\nChatbot:\")\n",
    "            \n",
    "            citations_flag = False\n",
    "            \n",
    "            for event in response:\n",
    "                                \n",
    "                # Text\n",
    "                if event.event_type == \"text-generation\":\n",
    "                    print(event.text, end=\"\")\n",
    "\n",
    "                # Citations\n",
    "                if event.event_type == \"citation-generation\":\n",
    "                    if not citations_flag:\n",
    "                        print(\"\\n\\nCITATIONS:\")\n",
    "                        citations_flag = True\n",
    "                    print(event.citations[0])\n",
    "            \n",
    "            # Documents\n",
    "            if citations_flag:\n",
    "                print(\"\\n\\nDOCUMENTS:\")\n",
    "                documents = [{'id': doc['id'],\n",
    "                                'text': doc['text'][:50] + '...',\n",
    "                                'title': doc['title'],\n",
    "                                'url': doc['url']} \n",
    "                                for doc in response.documents]\n",
    "                for doc in documents:\n",
    "                    print(doc)\n",
    "\n",
    "            print(f\"\\n{'-'*100}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hello\n",
      "\n",
      "Chatbot:\n",
      "Hi there! How can I help you today?\n",
      "\n",
      "If you would like, you can skip the small talk and get right to what you need assistance with. I'm a chatbot trained to be helpful, respectful and truthful, and I aim to make this conversation a pleasant and meaningful one for you :) \n",
      "\n",
      "Let me know if I can help you with anything specific, or you can even present me with a challenge!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "User: who are you\n",
      "Retrieving information...\n",
      "Chatbot:\n",
      "My name is Coral! I'm a large language model (LLM) developed by Cohere, and I'm designed to have polite, helpful, and inclusive conversations with users like you. I'm powered by Command, a powerful LLM built by Cohere.\n",
      "\n",
      "Currently, I'm only fluent in English, but models like me can be trained to understand and interpret various languages, too!\n",
      "\n",
      "CITATIONS:\n",
      "{'start': 64, 'end': 70, 'text': 'Cohere', 'document_ids': ['doc_0', 'doc_1', 'doc_2']}\n",
      "\n",
      "\n",
      "DOCUMENTS:\n",
      "{'id': 'doc_0', 'text': 'Most word and sentence embeddings are dependent on...', 'title': 'Text Embeddings', 'url': 'https://docs.cohere.com/docs/text-embeddings'}\n",
      "{'id': 'doc_1', 'text': 'However, word embeddings have a huge Achilles heel...', 'title': 'The Attention Mechanism', 'url': 'https://docs.cohere.com/docs/the-attention-mechanism'}\n",
      "{'id': 'doc_2', 'text': 'How to Use These Embeddings?\\n\\nNow that you’ve lear...', 'title': 'Text Embeddings', 'url': 'https://docs.cohere.com/docs/text-embeddings'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "User: embeddings\n",
      "Retrieving information...\n",
      "Chatbot:\n",
      "Embeddings are a way to associate vectors or lists of numbers with words or sentences, in a way that captures the semantic properties of the words or sentences in question.\n",
      "\n",
      "Word embeddings assign vectors to individual words, where the similarity between words is captured by the positional distance between their respective vectors. Sentence embeddings do the same thing but for entire sentences.\n",
      "\n",
      "Embeddings are super useful in language models because they enable us to measure the similarity between words or sentences, which can be used for tasks such as clustering and sorting.\n",
      "\n",
      "CITATIONS:\n",
      "{'start': 24, 'end': 85, 'text': 'associate vectors or lists of numbers with words or sentences', 'document_ids': ['doc_0', 'doc_1', 'doc_2']}\n",
      "{'start': 114, 'end': 133, 'text': 'semantic properties', 'document_ids': ['doc_0']}\n",
      "{'start': 174, 'end': 189, 'text': 'Word embeddings', 'document_ids': ['doc_0', 'doc_2']}\n",
      "{'start': 236, 'end': 333, 'text': 'similarity between words is captured by the positional distance between their respective vectors.', 'document_ids': ['doc_0', 'doc_2']}\n",
      "{'start': 334, 'end': 397, 'text': 'Sentence embeddings do the same thing but for entire sentences.', 'document_ids': ['doc_1', 'doc_2']}\n",
      "{'start': 459, 'end': 521, 'text': 'enable us to measure the similarity between words or sentences', 'document_ids': ['doc_1', 'doc_2']}\n",
      "\n",
      "\n",
      "DOCUMENTS:\n",
      "{'id': 'doc_0', 'text': 'In the previous chapter, I explained the concept o...', 'title': 'Similarity Between Words and Sentences', 'url': 'https://docs.cohere.com/docs/similarity-between-words-and-sentences'}\n",
      "{'id': 'doc_1', 'text': 'In the previous chapter, we learned that sentence ...', 'title': 'Similarity Between Words and Sentences', 'url': 'https://docs.cohere.com/docs/similarity-between-words-and-sentences'}\n",
      "{'id': 'doc_2', 'text': 'In the previous chapters, you learned about word a...', 'title': 'The Attention Mechanism', 'url': 'https://docs.cohere.com/docs/the-attention-mechanism'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ending chat.\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the Chatbot class with the Datastore instance\n",
    "chatbot = Chatbot(documents)\n",
    "\n",
    "# Run the chatbot\n",
    "chatbot.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
