{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Build a RAG-Powered Chatbot with Chat, Embed, and Rerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Read the accompanying [blog post here](https://txt.cohere.com/rag-chatbot).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Feature](images/rag-chatbot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you’ll learn how to build a chatbot that has RAG capabilities, enabling it to connect to external documents, ground its responses on these documents, and produce document citations in its responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a diagram that provides an overview of what we’ll build, followed by a list of the key steps involved.\n",
    "\n",
    "![Overview](images/rag-chatbot-flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup phase:\n",
    "- Step 0: Ingest the documents – get documents, chunk, embed, and index.\n",
    "\n",
    "For each user-chatbot interaction:\n",
    "- Step 1: Get the user message\n",
    "- Step 2: Call the Chat endpoint in query-generation mode\n",
    "- If at least one query is generated\n",
    "    - Step 3: Retrieve and rerank relevant documents\n",
    "    - Step 4: Call the Chat endpoint in document mode to generate a grounded response with citations\n",
    "- If no query is generated\n",
    "    - Step 4: Call the Chat endpoint in normal mode to generate a response\n",
    "\n",
    "Throughout the conversation:\n",
    "- Append the user-chatbot interaction to the conversation thread\n",
    "- Repeat with every interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install cohere hnswlib unstructured -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import hnswlib\n",
    "import json\n",
    "import uuid\n",
    "from typing import List, Dict\n",
    "from unstructured.partition.html import partition_html\n",
    "from unstructured.chunking.title import chunk_by_title\n",
    "\n",
    "co = cohere.Client(\"COHERE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Enable text wrapping in Google colab\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "def set_css():\n",
    "  display(HTML('''\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  '''))\n",
    "get_ipython().events.register('pre_run_cell', set_css)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documents component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Documents:\n",
    "    \"\"\"\n",
    "    A class representing a collection of documents.\n",
    "\n",
    "    Parameters:\n",
    "    sources (list): A list of dictionaries representing the sources of the documents. Each dictionary should have 'title' and 'url' keys.\n",
    "\n",
    "    Attributes:\n",
    "    sources (list): A list of dictionaries representing the sources of the documents.\n",
    "    docs (list): A list of dictionaries representing the documents, with 'title', 'content', and 'url' keys.\n",
    "    docs_embs (list): A list of the associated embeddings for the documents.\n",
    "    retrieve_top_k (int): The number of documents to retrieve during search.\n",
    "    rerank_top_k (int): The number of documents to rerank after retrieval.\n",
    "    docs_len (int): The number of documents in the collection.\n",
    "    index (hnswlib.Index): The index used for document retrieval.\n",
    "\n",
    "    Methods:\n",
    "    load(): Loads the data from the sources and partitions the HTML content into chunks.\n",
    "    embed(): Embeds the documents using the Cohere API.\n",
    "    index(): Indexes the documents for efficient retrieval.\n",
    "    retrieve(query): Retrieves documents based on the given query.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sources: List[Dict[str, str]]):\n",
    "        self.sources = sources\n",
    "        self.docs = []\n",
    "        self.docs_embs = []\n",
    "        self.retrieve_top_k = 10\n",
    "        self.rerank_top_k = 3\n",
    "        self.load()\n",
    "        self.embed()\n",
    "        self.index()\n",
    "\n",
    "    def load(self) -> None:\n",
    "        \"\"\"\n",
    "        Loads the documents from the sources and chunks the HTML content.\n",
    "        \"\"\"\n",
    "        print(\"Loading documents...\")\n",
    "\n",
    "        for source in self.sources:\n",
    "            elements = partition_html(url=source[\"url\"])\n",
    "            chunks = chunk_by_title(elements)\n",
    "            for chunk in chunks:\n",
    "                self.docs.append(\n",
    "                    {\n",
    "                        \"title\": source[\"title\"],\n",
    "                        \"text\": str(chunk),\n",
    "                        \"url\": source[\"url\"],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    def embed(self) -> None:\n",
    "        \"\"\"\n",
    "        Embeds the documents using the Cohere API.\n",
    "        \"\"\"\n",
    "        print(\"Embedding documents...\")\n",
    "\n",
    "        batch_size = 90\n",
    "        self.docs_len = len(self.docs)\n",
    "\n",
    "        for i in range(0, self.docs_len, batch_size):\n",
    "            batch = self.docs[i : min(i + batch_size, self.docs_len)]\n",
    "            texts = [item[\"text\"] for item in batch]\n",
    "            docs_embs_batch = co.embed(\n",
    "                texts=texts, model=\"embed-english-v3.0\", input_type=\"search_document\"\n",
    "            ).embeddings\n",
    "            self.docs_embs.extend(docs_embs_batch)\n",
    "\n",
    "    def index(self) -> None:\n",
    "        \"\"\"\n",
    "        Indexes the documents for efficient retrieval.\n",
    "        \"\"\"\n",
    "        print(\"Indexing documents...\")\n",
    "\n",
    "        self.idx = hnswlib.Index(space=\"ip\", dim=1024)\n",
    "        self.idx.init_index(max_elements=self.docs_len, ef_construction=512, M=64)\n",
    "        self.idx.add_items(self.docs_embs, list(range(len(self.docs_embs))))\n",
    "\n",
    "        print(f\"Indexing complete with {self.idx.get_current_count()} documents.\")\n",
    "\n",
    "    def retrieve(self, query: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Retrieves documents based on the given query.\n",
    "\n",
    "        Parameters:\n",
    "        query (str): The query to retrieve documents for.\n",
    "\n",
    "        Returns:\n",
    "        List[Dict[str, str]]: A list of dictionaries representing the retrieved documents, with 'title', 'text', and 'url' keys.\n",
    "        \"\"\"\n",
    "        docs_retrieved = []\n",
    "        query_emb = co.embed(\n",
    "            texts=[query], model=\"embed-english-v3.0\", input_type=\"search_query\"\n",
    "        ).embeddings\n",
    "\n",
    "        doc_ids = self.idx.knn_query(query_emb, k=self.retrieve_top_k)[0][0]\n",
    "\n",
    "        docs_to_rerank = []\n",
    "        for doc_id in doc_ids:\n",
    "            docs_to_rerank.append(self.docs[doc_id][\"text\"])\n",
    "\n",
    "        rerank_results = co.rerank(\n",
    "            query=query,\n",
    "            documents=docs_to_rerank,\n",
    "            top_n=self.rerank_top_k,\n",
    "            model=\"rerank-english-v2.0\",\n",
    "        )\n",
    "\n",
    "        doc_ids_reranked = []\n",
    "        for result in rerank_results:\n",
    "            doc_ids_reranked.append(doc_ids[result.index])\n",
    "\n",
    "        for doc_id in doc_ids_reranked:\n",
    "            docs_retrieved.append(\n",
    "                {\n",
    "                    \"title\": self.docs[doc_id][\"title\"],\n",
    "                    \"text\": self.docs[doc_id][\"text\"],\n",
    "                    \"url\": self.docs[doc_id][\"url\"],\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return docs_retrieved"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbot component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Chatbot:\n",
    "    \"\"\"\n",
    "    A class representing a chatbot.\n",
    "\n",
    "    Parameters:\n",
    "    docs (Documents): An instance of the Documents class representing the collection of documents.\n",
    "\n",
    "    Attributes:\n",
    "    conversation_id (str): The unique ID for the conversation.\n",
    "    docs (Documents): An instance of the Documents class representing the collection of documents.\n",
    "\n",
    "    Methods:\n",
    "    generate_response(message): Generates a response to the user's message.\n",
    "    retrieve_docs(response): Retrieves documents based on the search queries in the response.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, docs: Documents):\n",
    "        self.docs = docs\n",
    "        self.conversation_id = str(uuid.uuid4())\n",
    "\n",
    "    def generate_response(self, message: str):\n",
    "        \"\"\"\n",
    "        Generates a response to the user's message.\n",
    "\n",
    "        Parameters:\n",
    "        message (str): The user's message.\n",
    "\n",
    "        Yields:\n",
    "        Event: A response event generated by the chatbot.\n",
    "\n",
    "        Returns:\n",
    "        List[Dict[str, str]]: A list of dictionaries representing the retrieved documents.\n",
    "\n",
    "        \"\"\"\n",
    "        # Generate search queries (if any)\n",
    "        response = co.chat(message=message, search_queries_only=True)\n",
    "\n",
    "        # If there are search queries, retrieve documents and respond\n",
    "        # preamble_override = \"You only answer questions using on the documents you have provided with\"\n",
    "        \n",
    "        if response.search_queries:\n",
    "            print(\"Retrieving information...\")\n",
    "\n",
    "            documents = self.retrieve_docs(response)\n",
    "\n",
    "            response = co.chat(\n",
    "                message=message,\n",
    "                # preamble_override = preamble_override,\n",
    "                documents=documents,\n",
    "                conversation_id=self.conversation_id,\n",
    "                stream=True,\n",
    "            )\n",
    "            for event in response:\n",
    "                yield event\n",
    "            yield response\n",
    "\n",
    "        # If there is no search query, directly respond\n",
    "        else:\n",
    "            response = co.chat(\n",
    "                message=message,\n",
    "                # preamble_override = preamble_override,\n",
    "                conversation_id=self.conversation_id, \n",
    "                stream=True\n",
    "            )\n",
    "            for event in response:\n",
    "                yield event\n",
    "\n",
    "    def retrieve_docs(self, response) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Retrieves documents based on the search queries in the response.\n",
    "\n",
    "        Parameters:\n",
    "        response: The response object containing search queries.\n",
    "\n",
    "        Returns:\n",
    "        List[Dict[str, str]]: A list of dictionaries representing the retrieved documents.\n",
    "\n",
    "        \"\"\"\n",
    "        # Get the query(s)\n",
    "        queries = []\n",
    "        for search_query in response.search_queries:\n",
    "            queries.append(search_query[\"text\"])\n",
    "\n",
    "        # Retrieve documents for each query\n",
    "        retrieved_docs = []\n",
    "        for query in queries:\n",
    "            retrieved_docs.extend(self.docs.retrieve(query))\n",
    "\n",
    "        return retrieved_docs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### App component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class App:\n",
    "    def __init__(self, chatbot: Chatbot):\n",
    "        \"\"\"\n",
    "        Initializes an instance of the App class.\n",
    "\n",
    "        Parameters:\n",
    "        chatbot (Chatbot): An instance of the Chatbot class.\n",
    "\n",
    "        \"\"\"\n",
    "        self.chatbot = chatbot\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Runs the chatbot application.\n",
    "\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            # Get the user message\n",
    "            message = input(\"User: \")\n",
    "\n",
    "            # Typing \"quit\" ends the conversation\n",
    "            if message.lower() == \"quit\":\n",
    "                print(\"Ending chat.\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"User: {message}\")\n",
    "\n",
    "            # Get the chatbot response\n",
    "            response = self.chatbot.generate_response(message)\n",
    "\n",
    "            # Print the chatbot response\n",
    "            print(\"Chatbot:\")\n",
    "            \n",
    "            citations_flag = False\n",
    "            \n",
    "            for event in response:\n",
    "                stream_type = type(event).__name__\n",
    "                \n",
    "                # Text\n",
    "                if stream_type == \"StreamTextGeneration\":\n",
    "                    print(event.text, end=\"\")\n",
    "\n",
    "                # Citations\n",
    "                if stream_type == \"StreamCitationGeneration\":\n",
    "                    if not citations_flag:\n",
    "                        print(\"\\n\\nCITATIONS:\")\n",
    "                        citations_flag = True\n",
    "                    print(event.citations[0])\n",
    "                \n",
    "                # Documents\n",
    "                if citations_flag:\n",
    "                    if stream_type == \"StreamingChat\":\n",
    "                        print(\"\\n\\nDOCUMENTS:\")\n",
    "                        documents = [{'id': doc['id'],\n",
    "                                      'text': doc['text'][:50] + '...',\n",
    "                                      'title': doc['title'],\n",
    "                                      'url': doc['url']} \n",
    "                                      for doc in event.documents]\n",
    "                        for doc in documents:\n",
    "                            print(doc)\n",
    "\n",
    "            print(f\"\\n{'-'*100}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the sources for the documents\n",
    "# As an example, we'll use LLM University's Module 1: What are Large Language Models?\n",
    "# https://docs.cohere.com/docs/intro-large-language-models\n",
    "\n",
    "sources = [\n",
    "    {\n",
    "        \"title\": \"Text Embeddings\", \n",
    "        \"url\": \"https://docs.cohere.com/docs/text-embeddings\"},\n",
    "    {\n",
    "        \"title\": \"Similarity Between Words and Sentences\", \n",
    "        \"url\": \"https://docs.cohere.com/docs/similarity-between-words-and-sentences\"},\n",
    "    {\n",
    "        \"title\": \"The Attention Mechanism\", \n",
    "        \"url\": \"https://docs.cohere.com/docs/the-attention-mechanism\"},\n",
    "    {\n",
    "        \"title\": \"Transformer Models\", \n",
    "        \"url\": \"https://docs.cohere.com/docs/transformer-models\"}   \n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents...\n",
      "Embedding documents...\n",
      "Indexing documents...\n",
      "Indexing complete with 136 documents.\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the Documents class with the given sources\n",
    "documents = Documents(sources)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hello, I have a question\n",
      "Chatbot:\n",
      "Hello there! I'm happy to help with any questions or discussions you have in mind today. Go ahead and ask away, and I'll do my best to provide helpful, informative responses.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "User: What’s the difference between word and sentence embeddings\n",
      "Chatbot:\n",
      "Retrieving information...\n",
      "Word embeddings and sentence embeddings are both responsible for translating human language (words) into computer language (numbers).\n",
      "\n",
      "Word embeddings associate words with lists of numbers (vectors) in a way that similar words are grouped close together. Sentence embeddings do the same thing but for sentences, where similar sentences are grouped closer together.\n",
      "\n",
      "CITATIONS:\n",
      "{'start': 0, 'end': 15, 'text': 'Word embeddings', 'document_ids': ['doc_0', 'doc_1', 'doc_2']}\n",
      "{'start': 20, 'end': 39, 'text': 'sentence embeddings', 'document_ids': ['doc_0', 'doc_1', 'doc_2']}\n",
      "{'start': 65, 'end': 132, 'text': 'translating human language (words) into computer language (numbers)', 'document_ids': ['doc_2']}\n",
      "{'start': 135, 'end': 254, 'text': 'Word embeddings associate words with lists of numbers (vectors) in a way that similar words are grouped close together.', 'document_ids': ['doc_0']}\n",
      "{'start': 255, 'end': 310, 'text': 'Sentence embeddings do the same thing but for sentences', 'document_ids': ['doc_0', 'doc_1']}\n",
      "{'start': 318, 'end': 364, 'text': 'similar sentences are grouped closer together.', 'document_ids': ['doc_1']}\n",
      "\n",
      "\n",
      "DOCUMENTS:\n",
      "{'id': 'doc_0', 'text': 'In the previous chapters, you learned about word a...', 'title': 'The Attention Mechanism', 'url': 'https://docs.cohere.com/docs/the-attention-mechanism'}\n",
      "{'id': 'doc_1', 'text': 'This is where sentence embeddings come into play. ...', 'title': 'Text Embeddings', 'url': 'https://docs.cohere.com/docs/text-embeddings'}\n",
      "{'id': 'doc_2', 'text': 'Conclusion\\n\\nWord and sentence embeddings are the b...', 'title': 'Text Embeddings', 'url': 'https://docs.cohere.com/docs/text-embeddings'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "User: And what are their similarities\n",
      "Chatbot:\n",
      "Retrieving information...\n",
      "The similarities between word and sentence embeddings are that they both rely on vector representations of numerical values, and they both allow for calculations of similarity. Word embeddings focus on the similarity between individual words, whereas sentence embeddings compare entire sentences. \n",
      "\n",
      "The similarities between sentences can be calculated using cosine similarity, which is also the case for word embeddings. The similarity between each sentence and itself is always the highest (around 8000 for cosine similarity), while the similarity between different sentences is much lower.\n",
      "\n",
      "CITATIONS:\n",
      "{'start': 73, 'end': 123, 'text': 'rely on vector representations of numerical values', 'document_ids': ['doc_2']}\n",
      "{'start': 134, 'end': 176, 'text': 'both allow for calculations of similarity.', 'document_ids': ['doc_0', 'doc_1', 'doc_3', 'doc_4', 'doc_5']}\n",
      "{'start': 177, 'end': 241, 'text': 'Word embeddings focus on the similarity between individual words', 'document_ids': ['doc_0', 'doc_1', 'doc_3', 'doc_4', 'doc_5']}\n",
      "{'start': 251, 'end': 296, 'text': 'sentence embeddings compare entire sentences.', 'document_ids': ['doc_0', 'doc_1', 'doc_3', 'doc_4', 'doc_5']}\n",
      "{'start': 303, 'end': 375, 'text': 'similarities between sentences can be calculated using cosine similarity', 'document_ids': ['doc_0', 'doc_1', 'doc_3', 'doc_4', 'doc_5']}\n",
      "{'start': 404, 'end': 420, 'text': 'word embeddings.', 'document_ids': ['doc_0', 'doc_1', 'doc_3', 'doc_4', 'doc_5']}\n",
      "{'start': 425, 'end': 490, 'text': 'similarity between each sentence and itself is always the highest', 'document_ids': ['doc_5']}\n",
      "{'start': 491, 'end': 526, 'text': '(around 8000 for cosine similarity)', 'document_ids': ['doc_1', 'doc_3', 'doc_5']}\n",
      "{'start': 538, 'end': 591, 'text': 'similarity between different sentences is much lower.', 'document_ids': ['doc_0', 'doc_1', 'doc_3', 'doc_4']}\n",
      "\n",
      "\n",
      "DOCUMENTS:\n",
      "{'id': 'doc_2', 'text': 'One would expect the two first sentences to have a...', 'title': 'Similarity Between Words and Sentences', 'url': 'https://docs.cohere.com/docs/similarity-between-words-and-sentences'}\n",
      "{'id': 'doc_0', 'text': 'And the results are:\\n\\nThe similarity between sente...', 'title': 'Similarity Between Words and Sentences', 'url': 'https://docs.cohere.com/docs/similarity-between-words-and-sentences'}\n",
      "{'id': 'doc_1', 'text': 'This checks out as well! The similarity between se...', 'title': 'Similarity Between Words and Sentences', 'url': 'https://docs.cohere.com/docs/similarity-between-words-and-sentences'}\n",
      "{'id': 'doc_3', 'text': 'This checks out as well! The similarity between se...', 'title': 'Similarity Between Words and Sentences', 'url': 'https://docs.cohere.com/docs/similarity-between-words-and-sentences'}\n",
      "{'id': 'doc_4', 'text': 'And the results are:\\n\\nThe similarity between sente...', 'title': 'Similarity Between Words and Sentences', 'url': 'https://docs.cohere.com/docs/similarity-between-words-and-sentences'}\n",
      "{'id': 'doc_5', 'text': 'Just for consistency, let’s calculate the similari...', 'title': 'Similarity Between Words and Sentences', 'url': 'https://docs.cohere.com/docs/similarity-between-words-and-sentences'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "User: What do you know about graph neural networks\n",
      "Chatbot:\n",
      "Retrieving information...\n",
      "Graph neural networks are a newer concept in the world of neural networks. Using graph neural networks, programmers can develop models that analyze datasets comprised of pairs of entities and edges between those entities. These edges convey relationships between the entities, such as a connection between two entities or a similarity between entities. \n",
      "\n",
      "To construct graph neural networks, programmers use node embedding, a process that assigns a vector to each node in the graph. The vectors are designed so that their underlying information is preserved when compared to the original graph.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ending chat.\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the Chatbot class with the Documents instance\n",
    "chatbot = Chatbot(documents)\n",
    "\n",
    "# Create an instance of the App class with the Chatbot instance\n",
    "app = App(chatbot)\n",
    "\n",
    "# Run the chatbot\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
