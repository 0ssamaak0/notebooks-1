{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "060191b1",
      "metadata": {
        "id": "060191b1"
      },
      "source": [
        "# Fine-Tuning for Rerank\n",
        "\n",
        "Cohere's Rerank endpoint is a sophisticated semantic relevance scoring and ranking system that optimizes search results by evaluating the contextual relationship between queries and passages.\n",
        "\n",
        "However, complex domains are special challenge due to their intricate terminology, context, and domain-specific knowledge requirements. These domains include legal documents, medical research papers, scientific literature, technical manuals, developer documentation, code, financial reports, and other fields that demand a deep understanding of specific jargon and intricate concepts. These domains often necessitate fine-tuning on custom data to ensure the models capture the nuances and expertise essential for accurate comprehension.\n",
        "\n",
        "To understand the importance of domain-specific training, we will work with a code example utilizing a dataset in the legal domain. You'll see how fine-tuning can dramatically increase model accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09d21f23",
      "metadata": {
        "id": "09d21f23"
      },
      "source": [
        "## Overview\n",
        "\n",
        "We'll do the following steps:\n",
        "- **Step 1: Prepare the Dataset** - Download the dataset, select a subset, and prepare it for the Rerank endpoint.\n",
        "- **Step 2: Assess the Pre-Trained Model** - Calculate the test accuracy of the pre-trained model.\n",
        "- **Step 3: Fine-Tune the Model** - Kick off a fine-tuning job, and confirm when the model has completed training.\n",
        "- **Step 4: Evaluate the Fine-Tuned Model** - Evaluate the fine-tuned model's performance on the test dataset.\n",
        "\n",
        "## Setup\n",
        "\n",
        "We'll start by installing the tools we'll neeed and then importing them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2d454a21",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d454a21",
        "outputId": "e1e55d7a-ba32-4456-d0eb-0ee301ee808c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install cohere jsonlines datasets -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "58778a78",
      "metadata": {
        "id": "58778a78"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cohere\n",
        "import json\n",
        "import jsonlines\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53fef793",
      "metadata": {
        "id": "53fef793"
      },
      "source": [
        "Fill in your Cohere API key in the next cell. To do this, begin by [signing up to Cohere](https://os.cohere.ai/) (for free!) if you haven't yet. Then get your API key [here](https://dashboard.cohere.com/api-keys)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1e511ab6",
      "metadata": {
        "id": "1e511ab6"
      },
      "outputs": [],
      "source": [
        "# Paste your API key here. Remember to not share publicly\n",
        "co = cohere.Client(\"COHERE_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6188f278",
      "metadata": {
        "id": "6188f278"
      },
      "source": [
        "## Step 1: Prepare the Dataset\n",
        "\n",
        "We begin by downloading [the CaseHOLD dataset](https://huggingface.co/datasets/casehold/casehold) from Hugging Face. CaseHOLD is a multiple choice Q&A task consisting of legal decisions referencing other decisions as precedents, called a holding statement. It's a challenging task that demands specialized legal expertise to solve.\n",
        "\n",
        "<img src=\"https://txt.cohere.com/content/images/2023/09/Untitled.png\">\n",
        "\n",
        "We define it as an [IterableDataset](https://huggingface.co/docs/datasets/en/about_mapstyle_vs_iterable) to load only a small fraction of examples at a time and avoid loading the entire dataset in memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "45c7f8e0",
      "metadata": {
        "id": "45c7f8e0"
      },
      "outputs": [],
      "source": [
        "iterable_dataset = load_dataset(\"casehold/casehold\", split=\"train\", streaming=True, trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdc0f31d",
      "metadata": {
        "id": "cdc0f31d"
      },
      "source": [
        "For this example, we'll use a subset of only 2000 data points, to be split across training, validation and test sets.\n",
        "\n",
        "The data is stored in a Pandas DataFrame `df` with 5 columns:\n",
        "- `\"query\"` - The search query or question (in the image above, this corresponds to the \"citing text\" or \"prompt\")\n",
        "- `\"docs\"` - A list of five documents, where only one correctly answers the query (in the image above, all five \"holding statements\")\n",
        "- `\"label\"` - The index of the document that correctly answers the query (in the example in the image above, would be \"0\", corresponding to holding statement 0)\n",
        "- `\"relevant_passages\"` - The document that correctly answers the query\n",
        "- `\"hard_negatives\"`- The four documents that don't correctly answer the query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ad4f4077",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "ad4f4077",
        "outputId": "05f55617-e671-4220-e4d1-50c7125309ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               query  \\\n",
              "0  Drapeau’s cohorts, the cohort would be a “vict...   \n",
              "1  Colameta used customer information that he too...   \n",
              "2  property tax sale. In reviewing section 6323(b...   \n",
              "3  They also rely on Oswego Laborers’ Local 214 P...   \n",
              "4  did not affect the defendant’s guideline range...   \n",
              "\n",
              "                                                docs  label  \\\n",
              "0  [holding that possession of a pipe bomb is a c...      0   \n",
              "1  [recognizing that even if a plaintiff claims c...      1   \n",
              "2  [holding that where there is a conflict betwee...      4   \n",
              "3  [holding that plaintiff stated a  349 claim wh...      0   \n",
              "4  [holding that united states v booker 543 us 22...      3   \n",
              "\n",
              "                                   relevant_passages  \\\n",
              "0  [holding that possession of a pipe bomb is a c...   \n",
              "1  [holding that included among trade secrets emp...   \n",
              "2  [holding that a specific statutory provision p...   \n",
              "3  [holding that plaintiff stated a  349 claim wh...   \n",
              "4  [holding that united states v booker 543 us 22...   \n",
              "\n",
              "                                      hard_negatives  \n",
              "0  [holding that bank robbery by force and violen...  \n",
              "1  [recognizing that even if a plaintiff claims c...  \n",
              "2  [holding that where there is a conflict betwee...  \n",
              "3  [holding that plaintiff stated a claim for bre...  \n",
              "4  [holding that united states v booker 543 us 22...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-226e4c47-1fde-4e65-a70b-8a79686c08b1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>docs</th>\n",
              "      <th>label</th>\n",
              "      <th>relevant_passages</th>\n",
              "      <th>hard_negatives</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Drapeau’s cohorts, the cohort would be a “vict...</td>\n",
              "      <td>[holding that possession of a pipe bomb is a c...</td>\n",
              "      <td>0</td>\n",
              "      <td>[holding that possession of a pipe bomb is a c...</td>\n",
              "      <td>[holding that bank robbery by force and violen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Colameta used customer information that he too...</td>\n",
              "      <td>[recognizing that even if a plaintiff claims c...</td>\n",
              "      <td>1</td>\n",
              "      <td>[holding that included among trade secrets emp...</td>\n",
              "      <td>[recognizing that even if a plaintiff claims c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>property tax sale. In reviewing section 6323(b...</td>\n",
              "      <td>[holding that where there is a conflict betwee...</td>\n",
              "      <td>4</td>\n",
              "      <td>[holding that a specific statutory provision p...</td>\n",
              "      <td>[holding that where there is a conflict betwee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>They also rely on Oswego Laborers’ Local 214 P...</td>\n",
              "      <td>[holding that plaintiff stated a  349 claim wh...</td>\n",
              "      <td>0</td>\n",
              "      <td>[holding that plaintiff stated a  349 claim wh...</td>\n",
              "      <td>[holding that plaintiff stated a claim for bre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>did not affect the defendant’s guideline range...</td>\n",
              "      <td>[holding that united states v booker 543 us 22...</td>\n",
              "      <td>3</td>\n",
              "      <td>[holding that united states v booker 543 us 22...</td>\n",
              "      <td>[holding that united states v booker 543 us 22...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-226e4c47-1fde-4e65-a70b-8a79686c08b1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-226e4c47-1fde-4e65-a70b-8a79686c08b1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-226e4c47-1fde-4e65-a70b-8a79686c08b1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b55b166a-f1b4-4f21-a316-65e3fd6d329c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b55b166a-f1b4-4f21-a316-65e3fd6d329c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b55b166a-f1b4-4f21-a316-65e3fd6d329c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2000,\n  \"fields\": [\n    {\n      \"column\": \"query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          \"case. We conclude, based upon Rambert and Nobles, that the evidence here supported three separate charges against defendant McDaniel. Consequently, the trial court did not err in entering three judgments against defendant McDaniel for discharging a weapon into occupied property. Defendant McDaniel also argues that he received ineffective assistance of counsel because his trial counsel failed to move, based on double jeopardy grounds, to arrest judgment on two counts of discharging a weapon into occupied property. Since we have concluded that defendant McDaniel could properly be convicted of and sentenced for all three counts, he cannot show that his attorney failed to provide effective assistance of counsel. See State v. Brewton, 173 N.C. App. 323, 333, 618 S.E.2d 850, 858 (2005) (<HOLDING>). We, therefore, conclude defendants received a\",\n          \"compliance with such a complex set of requirements is practically impossible, and we will not infer congressional intent that a state achieve the impossible\\u201d), rev\\u2019d on other grounds, Frew v. Hawkins, 540 U.S. 431, 436, 124 S.Ct. 899, 157 L.Ed.2d 855 (2004). Rather, we consider whether it is absolutely clear that a systemic computer problem of the type that caused Unan\\u2019s and Quintino\\u2019s injuries could not reasonably be expected to recur. Defendant failed to put forward sufficient evidence to meet this standard. Although there is evidence that DHHS took significant steps to correct the systemic problem, evidence of substantial compliance does not moot a case unless it is \\u201cabsolutely clear\\u201d that the violations could not reasonably recur. See Laidlaw, 528 U.S. at 193, 120 S.Ct. 693 (<HOLDING>). Here, defendant argues that by the end of\",\n          \"16(b)(2) would not preclude its discovery, for we understand this provision only to state the limits of discovery under the authority of Rule 16, not the limits of the court\\u2019s potential discovery powers. See Middleton v. United States, 401 A.2d 109, 116-20 (D.C.1979) (noting that while \\\"any venture beyond the[ ] limited principles [of the Jencks Act and Rule 16 discovery] must be subjected to close scrutiny,\\u201d more extensive disclosure may be sustained \\u201d[i]n proper circumstances\\u201d under the court\\u2019s \\u201c\\u2018inherent powers' over the discovery process\\\"). Furthermore, to the extent that our ruling here authorizes discovery during trial, Rule 16 is irrelevant, for it applies only to pretrial discovery. See United States v. Nobles, 422 U.S. 225, 234-35, 95 S.Ct. 2160, 2168-69, 45 L.Ed.2d 141 (1975) (<HOLDING>); Waldron v. United States, 370 A.2d 1372, 1373\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"docs\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          2,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"relevant_passages\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hard_negatives\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Size of data subset\n",
        "num_examples = 2000\n",
        "\n",
        "# Labels for columns containing the 5 documents in raw dataset file\n",
        "all_labels = [\"holding_\" + s for s in [\"0\", \"1\", \"2\", \"3\", \"4\"]]\n",
        "\n",
        "# Instantiate list containing the data\n",
        "d = []\n",
        "\n",
        "# Store each dataset entry as dictionary within Python list\n",
        "for example in iterable_dataset.take(num_examples):\n",
        "    selected_passage_idx = \"holding_{}\".format(example[\"label\"])\n",
        "    hard_negatives_idx = [x for x in all_labels if x != selected_passage_idx]\n",
        "    d.append(\n",
        "        {\n",
        "            'query': example[\"citing_prompt\"],\n",
        "            'docs': [example.get(key) for key in all_labels],\n",
        "            'label': int(example[\"label\"]),\n",
        "            'relevant_passages': [example[selected_passage_idx]],\n",
        "            'hard_negatives': [example.get(key) for key in hard_negatives_idx]\n",
        "        }\n",
        "    )\n",
        "\n",
        "# Convert list to Pandas dataframe, preview the dataframe\n",
        "df = pd.DataFrame(d)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ff54b7c",
      "metadata": {
        "id": "9ff54b7c"
      },
      "source": [
        "We do a train-validation-test-split with a ratio of 75% for training (in `df_train`), 15% for validation (in `df_valid)`, and 10% for testing (in `df_test`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ee4b9053",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee4b9053",
        "outputId": "71e3ce6f-68f7-4567-b3f6-696a79eaf43a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of training set: 1500\n",
            "Size of validation set: 300\n",
            "Size of teset set: 200\n"
          ]
        }
      ],
      "source": [
        "# Set ratios for train-valid-test split (should sum to 1)\n",
        "train_ratio = 0.75\n",
        "valid_ratio = 0.15\n",
        "test_ratio = 0.10\n",
        "\n",
        "# Do train-validation-test split\n",
        "df_train, df_val_test = train_test_split(df, test_size = 1 - train_ratio)\n",
        "df_valid, df_test = train_test_split(df_val_test, test_size=test_ratio/(test_ratio + valid_ratio))\n",
        "\n",
        "print('Size of training set:', len(df_train))\n",
        "print('Size of validation set:', len(df_valid))\n",
        "print('Size of teset set:', len(df_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "723e4906",
      "metadata": {
        "id": "723e4906"
      },
      "source": [
        "## Step 2: Assess the Pre-Trained Model\n",
        "\n",
        "We'll now check the test accuracy of the pre-trained model. The `get_prediction()` function looks at a test example and uses the pre-trained model to predict the index of the document that it believes correctly answers the query.\n",
        "\n",
        "To get predictions, we'll use the [`rerank()` method](https://docs.cohere.com/reference/rerank-1) of the Cohere client and supply four arguments:\n",
        "- `model` - Defaults to [`rerank-english-v2.0`](https://docs.cohere.com/docs/rerank-2), Cohere's pre-trained model for re-ranking English language documents\n",
        "- `query` - The search query or question\n",
        "- `documents` - List of documents to choose from\n",
        "- `top_n` - Number of documents to return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a6cc999d",
      "metadata": {
        "id": "a6cc999d"
      },
      "outputs": [],
      "source": [
        "# Predict index of document that corrrectly answers query\n",
        "def get_prediction(item, model=\"rerank-english-v2.0\"):\n",
        "    response = co.rerank(model=model,\n",
        "                         query=item[\"query\"],\n",
        "                         documents=item[\"docs\"],\n",
        "                         top_n=1)\n",
        "    prediction = response.results[0].index\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a49c3012",
      "metadata": {
        "id": "a49c3012"
      },
      "source": [
        "We apply this function to every row in the test set and save the predictions in new column `\"baseline_prediction\"`. Then, to calculate the test accuracy, we compare the predictions to the ground truth labels in the `\"label\"` column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c038e0c0",
      "metadata": {
        "id": "c038e0c0",
        "outputId": "d9c3f41e-9122-40b0-e70f-ea1cddfa98b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline accuracy: 0.325\n"
          ]
        }
      ],
      "source": [
        "# Calculate pre-trained model's test accuracy\n",
        "df_test[\"baseline_prediction\"] = df_test.apply(get_prediction, axis=1)\n",
        "print(\"Baseline accuracy:\", sum(df_test[\"baseline_prediction\"] == df_test[\"label\"])/len(df_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64427505",
      "metadata": {
        "id": "64427505"
      },
      "source": [
        "The model does better than random guessing (which would yield an accuracy of 25%), but we can do significantly better with fine-tuning.\n",
        "\n",
        "## Step 3: Fine-Tune the Model\n",
        "\n",
        "To prepare for fine-tuning with the Rerank endpoint, we'll need to convert the data to jsonl format, where each row is an example with three items:\n",
        "- `\"query\"` - The search query or question\n",
        "- `\"relevant_passages\"` - The document that correctly answers the query\n",
        "- `\"hard_negatives\"`- The four documents that incorrectly answer the query\n",
        "\n",
        "We do this separately for training and validation data. You can learn more about preparing the Rerank fine-tuning data in [the documentation](https://docs.cohere.com/docs/rerank-preparing-the-data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "203e0995",
      "metadata": {
        "id": "203e0995"
      },
      "outputs": [],
      "source": [
        "# Arranges the data to suit Cohere's format\n",
        "def create_rerank_ft_data(query, relevant_passages, hard_negatives):\n",
        "    formatted_data = {\n",
        "        \"query\": query,\n",
        "        \"relevant_passages\": relevant_passages,\n",
        "        \"hard_negatives\": hard_negatives\n",
        "    }\n",
        "    return formatted_data\n",
        "\n",
        "# Creates jsonl file if does not already exist\n",
        "def create_jsonl_from_list(file_name, df):\n",
        "    path = f'{file_name}.jsonl'\n",
        "    if not os.path.isfile(path):\n",
        "        with open(path, 'w+') as file:\n",
        "            for idx, row in df.iterrows():\n",
        "                formatted_data = create_rerank_ft_data(row[\"query\"], row[\"relevant_passages\"], row[\"hard_negatives\"])\n",
        "                file.write(json.dumps(formatted_data) + '\\n')\n",
        "            file.close()\n",
        "\n",
        "# Create training and validation jsonl files\n",
        "create_jsonl_from_list(\"casehold_train\", df_train)\n",
        "create_jsonl_from_list(\"casehold_valid\", df_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d12485b",
      "metadata": {
        "id": "9d12485b"
      },
      "source": [
        "Next, we preview the first couple lines of the training file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "104016d2",
      "metadata": {
        "id": "104016d2",
        "outputId": "e4467558-b2c7-446f-ac18-caa203d6f7f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'query': 'other circuits which indicate that the failure to provide such notice is reversible error, as the parties may have engaged in a different trial strategy had they known of the jury\\'s advisory capacity. See Thompson v. Parkes, 963 F.2d 885, 888 (6th Cir.1992) (examining the plain language of the rule and policy considerations of trial tactics and concluding \"the rule requires that the court’s initiative in ordering a trial to an advisory jury must occur, and the parties be made aware of it, before the case is submitted”); Bereda v. Pickering Creek Indus. Park, Inc., 865 F.2d 49, 53 (3d Cir.1989) (requiring a district court to \"notify both sides of a jury\\'s advisory status no later than the time at which the jury selection has begun”); Pradier v. Elespuru, 641 F.2d 808, 811 (9th Cir.1981) (<HOLDING>); cf. Merex A.G. v. Fairchild Weston Sys.,', 'relevant_passages': ['recognizing that there are frequently significant tactical differences in presenting a case to a court as opposed to a jury the parties are entitled to know at the outset of the trial whether the decision will be made by the judge or the jury'], 'hard_negatives': ['recognizing the right to waive a jury trial', 'recognizing that a district attorney must have reasonable latitude in fairly presenting a case to the jury and that the trial judge must have reasonable discretion in deciding whether the bounds of propriety have been exceeded', 'holding that where the meaning of the jurys verdict was not clear in light of the trial courts jury instructions the court of appeals erred in directing entry of judgment for respondent the case should have been remanded to the trial judge who was in the best position to pass upon the question of a new trial in light of the evidence his charge to the jury and the jurys verdict', 'holding that the trial judge rather than the jury makes the determination of whether the defendant violated the implied consent law']}\n",
            "{'query': 'Raye Ellen Stiles appeals pro se from the district court’s summary judgment in her action alleging, among other claims, housing discrimination. We have jurisdiction under 28 U.S.C. § 1291. We review de novo and may affirm the district court on any ground supported by the record. Crowley v. Nevada, 678 F.3d 730, 733-34 (9th Cir.2012). We affirm. Summary judgment on Stiles’ claims for intentional infliction of emotional distress, aggravation of preexisting conditions, and public humiliation was proper because she already litigated these claims in Arizona state court, and, thus, res judicata precludes her from bringing such claims in federal court. See Sunkist Growers v. Fisher, 104 F.3d 280, 283-84 (9th Cir.1997) (<HOLDING>). Summary judgment on Stiles’ federal claims', 'relevant_passages': ['holding that under arizona law a litigant may not bring a claim identical to one she has previously litigated'], 'hard_negatives': ['holding that a person has standing to bring suit under the civil rights act if she or he can show that she or he was punished for trying to vindicate the rights of minorities', 'holding that plaintiff had standing to bring a rico conspiracy claim despite his inability to bring a substantive rico claim', 'holding that while parents may not bring a title ix claim as individuals they may bring such claim on behalf of a deceased child', 'holding that plaintiffs may bring a section 1983 claim for damages to vindicate their rights under idea']}\n"
          ]
        }
      ],
      "source": [
        "# List the first 2 items in the training jsonl file\n",
        "with jsonlines.open('casehold_train.jsonl') as f:\n",
        "    [print(line) for _, line in zip(range(2), f)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6e291f0",
      "metadata": {
        "id": "c6e291f0"
      },
      "source": [
        "We kick off a fine-tuning job by navigating to the fine-tuning tab of the Dashboard. Under \"Rerank\", click on \"Create a Rerank model\".\n",
        "\n",
        "<img src=\"https://files.readme.io/48dad78-cohere_dashboard.png\">\n",
        "\n",
        "Next, upload the .jsonl files you just created as the training and validation sets by clicking on the \"TRAINING SET\" and \"VALIDATION SET\" buttons. When ready, click on \"Review data\" to proceed to the next step.\n",
        "\n",
        "<img src=\"https://files.readme.io/4522c16-rerank-review-data.png\">\n",
        "\n",
        "Then, you'll see a preview of how the model will ingest your data. If anything is wrong with the data, the page will also provide suggested changes to fix the training file. Otherwise, if everything looks good, you can proceed to the next step.\n",
        "\n",
        "<img src=\"https://files.readme.io/3becc26-rerank-create-finetune.png\">\n",
        "\n",
        "Finally, you'll provide a nickname for your model. We used `casehold-rerank-ft` as the nickname for our model. This page also allows you to provide custom values for the hyperparameters used during training, but we'll keep them at the default values for now.\n",
        "\n",
        "<img src=\"https://files.readme.io/ea79369-casehold-rerank-ft.png\">\n",
        "\n",
        "Once you have filled in a name, click on \"Start training\" to kick off the fine-tuning process. This will navigate you to a page where you can monitor the status of the model. A model that has finished fine-tuning will show the status as `READY`.\n",
        "\n",
        "[image - need to take]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71fa23b6",
      "metadata": {
        "id": "71fa23b6"
      },
      "source": [
        "## Step 4: Evaluate the Fine-Tuned Model\n",
        "\n",
        "Once the model has completed the fine-tuning process, it’s time to evaluate its performance.\n",
        "\n",
        "Navigate to the API tab of the fine-tuned model. There, you'll see the model ID that you should use when calling `co.rerank()`.\n",
        "\n",
        "[image - need to take]\n",
        "\n",
        "In the following code, we calculate the test accuracy of the fine-tuned model. We use the same `get_prediction()` function as before, but now just need to pass in the fine-tuned model ID."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cfa4c1dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfa4c1dc",
        "outputId": "100ce912-180c-4ab7-8fee-5af71e83ab2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tune accuracy: 0.675\n"
          ]
        }
      ],
      "source": [
        "# Calculate fine-tuned model's test accuracy\n",
        "df_test['ft_prediction'] = df_test.apply(get_prediction, model='48be5fa4-b16f-4fa4-baa7-a5023daa8af5-ft', axis=1)\n",
        "print(\"Fine-tune accuracy:\", sum(df_test[\"ft_prediction\"] == df_test[\"label\"])/len(df_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a39d88a5",
      "metadata": {
        "id": "a39d88a5"
      },
      "source": [
        "This is a meaningful increase in accuracy, and we could improve performance even more by increasing the size of the training data!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}