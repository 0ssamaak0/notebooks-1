{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/cohere-ai/notebooks/blob/main/notebooks/llmu/Parameters_for_Controlling_Outputs.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters for Controlling Outputs\n",
    "\n",
    "In this notebook, youâ€™ll learn about the parameters you can use to control the Chat endpoint's outputs.\n",
    "\n",
    "*Read the accompanying [blog post here](https://docs.cohere.com/docs/parameters-for-controlling-outputs).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook has 2 sections:\n",
    "- **Model Type** - Select a variation of the Command model.\n",
    "- **Randomness** - Use the `temperature` parameter to control the level of randomness of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by installing the tools we'll need and then importing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z49_e7Ma2IgU",
    "outputId": "877c1228-c424-433f-d22c-1565c8445d35"
   },
   "outputs": [],
   "source": [
    "! pip install cohere -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Enable text wrapping in Google Colab\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "def set_css():\n",
    "  display(HTML('''\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  '''))\n",
    "get_ipython().events.register('pre_run_cell', set_css)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in your Cohere API key in the next cell. To do this, begin by [signing up to Cohere](https://os.cohere.ai/) (for free!) if you haven't yet. Then get your API key [here](https://dashboard.cohere.com/api-keys)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cohere\n",
    "\n",
    "# Paste your API key here. Remember to not share publicly\n",
    "co = cohere.Client(\"COHERE_API_KEY\") # Insert your Cohere API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Type\n",
    "\n",
    "When calling the Chat endpoint, use the `model` parameter to choose from several variations of the Command model. In the example, we select [Command R+](https://docs.cohere.com/docs/command-r-plus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "response = co.chat(message=\"Hello\",\n",
    "                   model=\"command-r-plus\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Df4lLD-P3aj_"
   },
   "source": [
    "[See the documentation](https://docs.cohere.com/docs/models#command) for the most updated list of available Cohere models.\n",
    "\n",
    "## Randomness\n",
    "\n",
    "You can use the `temperature` parameter to control the level of randomness of the model. It is a value between 0 and 1. As you increase the temperature, the model gets more creative and random. Temperature can be tuned for different problems, and most people will find that the default temperature of 0.3 is a good starting point.\n",
    "\n",
    "Consider the example below, where we ask the model to generate alternative titles for a blog post. Prompting the endpoint five times when the temperature is set to 0 yields the same output each time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Future of AI: Unlocking the Power of Retrieval-Augmented Generation\n",
      "The Future of AI: Unlocking the Power of Retrieval-Augmented Generation\n",
      "The Future of AI: Unlocking the Power of Retrieval-Augmented Generation\n",
      "The Future of AI: Unlocking the Power of Retrieval-Augmented Generation\n",
      "The Future of AI: Unlocking the Power of Retrieval-Augmented Generation\n"
     ]
    }
   ],
   "source": [
    "message = \"\"\"Suggest a more exciting title for a blog post titled: Intro to Retrieval-Augmented Generation. \\\n",
    "Respond in a single line.\"\"\"\n",
    "\n",
    "for _ in range(5):\n",
    "    response = co.chat(message=message,\n",
    "                       temperature=0,\n",
    "                       model=\"command-r-plus\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we increase the temperature to the maximum value of 1, the model gives different proposals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unleashing the Power of Retrieval-Augmented Generation: A Comprehensive Guide\n",
      "The Exciting Future of AI: How Retrieval-Augmented Generation Will Transform the Way We Interact With Machines\n",
      "The Magic of AI: Unlocking the Power of Retrieval-Augmented Generation\n",
      "The Future of AI: Unlocking the Power of Retrieval-Augmented Generation\n",
      "\"Unleashing the Power of AI: The Rise of Retrieval-Augmented Generation.\"\n"
     ]
    }
   ],
   "source": [
    "message = \"\"\"Suggest a more exciting title for a blog post titled: Intro to Retrieval-Augmented Generation. \\\n",
    "Respond in a single line.\"\"\"\n",
    "\n",
    "for _ in range(5):\n",
    "    response = co.chat(message=message,\n",
    "                       temperature=1,\n",
    "                       model=\"command-r-plus\")\n",
    "    print(response.text)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
