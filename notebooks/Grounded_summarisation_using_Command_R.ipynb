{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAjb3BOMsYjE"
      },
      "source": [
        "# Long-form summarization with citations using grounded generation\n",
        "\n",
        "This notebook provides the code to produce the outputs described in [this blog post](https://docs.google.com/document/d/1Eeakpz_FZoeMzJnQieqQWCpPtQuNiTGW4fueU9J0QHA/edit).\n",
        "\n",
        "## Table of contents\n",
        "\n",
        "1. [Setup](#setup)\n",
        "2. [Out-of-the-box summarization with Command-R](#out-of-the-box-summarization-with-command-r)\n",
        "3. [Introduce citations to the summary for grounding](#introduce-citations-to-the-summary-for-grounding)\n",
        "4. [Reduce the cost of summarization calls](#reduce-the-cost-of-summarization-calls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF9yEHUFt9up"
      },
      "source": [
        "<a id=\"setup\"></a>\n",
        "<a name=\"setup\"></a>\n",
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8CjM6c8EnVK",
        "outputId": "51acb907-2567-49f7-95df-85114dc975e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Cohere API key: ··········\n"
          ]
        }
      ],
      "source": [
        "%%capture\n",
        "!pip install cohere networkx\n",
        "\n",
        "import cohere\n",
        "import networkx as nx\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import numpy as np\n",
        "import spacy\n",
        "\n",
        "from collections import deque\n",
        "from getpass import getpass\n",
        "import re\n",
        "from typing import List, Tuple\n",
        "\n",
        "# Set up Cohere client\n",
        "co_api_key = getpass(\"Enter your Cohere API key: \")\n",
        "co_model = \"command-r\"\n",
        "co = cohere.Client(co_api_key)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2DBeeGTEnya",
        "outputId": "93a5f50a-f1db-445b-c0e3-2a619975da61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Loaded IMF report with 28573 tokens\n"
          ]
        }
      ],
      "source": [
        "# Read IMF report\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "fpath = \"drive/Shareddrives/FDE/Cookbooks/Long-form summarisation/ai_and_future_of_work.txt\"\n",
        "with open(fpath, \"r\") as f:\n",
        "  text = f.read()\n",
        "\n",
        "num_tokens = co.tokenize(text).length\n",
        "print(f\"Loaded IMF report with {num_tokens} tokens\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xe2TzS6q28D6"
      },
      "source": [
        "### Aside: define utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFkiLPTIzZw4"
      },
      "outputs": [],
      "source": [
        "# Utils!\n",
        "\n",
        "# --- for chunking ---\n",
        "def split_text_into_sentences(text: str) -> List[str]:\n",
        "    sentences =  sent_tokenize(text)\n",
        "    return sentences\n",
        "\n",
        "def group_sentences_into_passages(sentence_list: List[str], n_sentences_per_passage: int = 10):\n",
        "    \"\"\"\n",
        "    Group sentences into passages of n_sentences sentences.\n",
        "    \"\"\"\n",
        "    passages = []\n",
        "    passage = \"\"\n",
        "    for i, sentence in enumerate(sentence_list):\n",
        "        passage += sentence + \" \"\n",
        "        if (i + 1) % n_sentences_per_passage == 0:\n",
        "            passages.append(passage)\n",
        "            passage = \"\"\n",
        "    return passages\n",
        "\n",
        "def build_simple_chunks(text, n_sentences: int = 10):\n",
        "    \"\"\"\n",
        "    Build chunks of text from the input text.\n",
        "    \"\"\"\n",
        "    sentences = split_text_into_sentences(text)\n",
        "    chunks = group_sentences_into_passages(sentences, n_sentences_per_passage=n_sentences)\n",
        "    return chunks\n",
        "\n",
        "\n",
        "# --- for visualising citations ---\n",
        "\n",
        "def insert_citations(text: str, citations: List[dict]):\n",
        "    \"\"\"\n",
        "    A helper function to pretty print citations.\n",
        "    \"\"\"\n",
        "    offset = 0\n",
        "    # Process citations in the order they were provided\n",
        "    for citation in citations:\n",
        "        # Adjust start/end with offset\n",
        "        start, end = citation['start'] + offset, citation['end'] + offset\n",
        "        placeholder = \"[\" + \", \".join(doc[4:] for doc in citation[\"document_ids\"]) + \"]\"\n",
        "        # ^ doc[4:] removes the 'doc_' prefix, and leaves the quoted document\n",
        "        modification = f'{text[start:end]} {placeholder}'\n",
        "        # Replace the cited text with its bolded version + placeholder\n",
        "        text = text[:start] + modification + text[end:]\n",
        "        # Update the offset for subsequent replacements\n",
        "        offset += len(modification) - (end - start)\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "# --- for reducing number of tokens sent to model intelligently ---\n",
        "\n",
        "def textrank(text: str, co, max_tokens: int, n_sentences_per_passage: int) -> str:\n",
        "    \"\"\"\n",
        "    Shortens `text` by extracting key units of text from `text` based on their centrality and concatenating them.\n",
        "    The output is the concatenation of those key units, in their original order. Centrality is graph-theoretic\n",
        "    measure of connectedness of a node; the more connected a node is to surrounding nodes (and the more sparsely\n",
        "    those neighbours are connected), the higher centrality.\n",
        "\n",
        "    Key passages are identified via clustering in a three-step process:\n",
        "    1. Break up `long` into chunks (either sentences or passages, based on `unit`)\n",
        "    2. Embed each chunk using Cohere's embedding model and construct a similarity matrix\n",
        "    3. Compute the centrality of each chunk\n",
        "    4. Keep the highest-centrality chunks until `max_tokens` is reached\n",
        "    5. Put together shorterned text by reordering chunks in their original order\n",
        "\n",
        "    This approach is based on summarise.long_doc_summarization.extraction::extract_single_doc with sorting by\n",
        "    centrality. Adapted here because installing the `summarise` repo would have added a lot of unused functionalities\n",
        "    and dependencies.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Chunk text into units\n",
        "    chunks = build_simple_chunks(text, n_sentences_per_passage)\n",
        "\n",
        "    # 2. Embed and construct similarity matrix\n",
        "    embeddings = np.array(\n",
        "        co.embed(\n",
        "            texts=chunks,\n",
        "            model=\"embed-english-v3.0\",\n",
        "            input_type=\"clustering\",\n",
        "        ).embeddings\n",
        "    )\n",
        "    similarities = np.dot(embeddings, embeddings.T)\n",
        "\n",
        "    # 3. Compute centrality and sort sentences by centrality\n",
        "    # Easiest to use networkx's `degree` function with similarity as weight\n",
        "    g = nx.from_numpy_array(similarities, edge_attr=\"weight\")\n",
        "    centralities = g.degree(weight=\"weight\")\n",
        "    idcs_sorted_by_centrality = [node for node, degree in sorted(centralities, key=lambda item: item[1], reverse=True)]\n",
        "\n",
        "    # 4. Add chunks back in order of centrality\n",
        "    selected = _add_chunks_by_priority(co, chunks, idcs_sorted_by_centrality, max_tokens)\n",
        "\n",
        "    # 5. Put condensed text back in original order\n",
        "    separator = \"\\n\"\n",
        "    short = separator.join([chunk for index, chunk in sorted(selected, key=lambda item: item[0], reverse=False)])\n",
        "\n",
        "    return short\n",
        "\n",
        "\n",
        "def _add_chunks_by_priority(\n",
        "    co, chunks: List[str], idcs_sorted_by_priority: List[int], max_tokens: int\n",
        ") -> List[Tuple[int, str]]:\n",
        "    \"\"\"\n",
        "    Given chunks of text and their indices sorted by priority (highest priority first), this function\n",
        "    fills the model context window with as many highest-priority chunks as possible.\n",
        "\n",
        "    The output is a list of (index, chunk) pairs, ordered by priority. To stitch back the chunks into\n",
        "    a cohesive text that preserves chronological order, sort the output on its index.\n",
        "    \"\"\"\n",
        "\n",
        "    selected = []\n",
        "    num_tokens = 0\n",
        "    idcs_queue = deque(idcs_sorted_by_priority)\n",
        "\n",
        "    while num_tokens < max_tokens and len(idcs_queue) > 0:\n",
        "        next_idx = idcs_queue.popleft()\n",
        "        num_tokens += co.tokenize(chunks[next_idx]).length - 2\n",
        "        # num_tokens += len(tokenizer.encode(chunks[next_idx]).ids) - 2\n",
        "        # ^ removing BOS and EOS tokens from count\n",
        "        selected.append((next_idx, chunks[next_idx]))\n",
        "        # ^ keep index and chunk, to reorder chronologically\n",
        "    if num_tokens > max_tokens:\n",
        "        selected.pop()\n",
        "\n",
        "    return selected\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMt7yd7z3Gth"
      },
      "source": [
        "<a id=\"out-of-the-box-summarization-with-command-r\"></a>\n",
        "<a name=\"out-of-the-box-summarization-with-command-r\"></a>\n",
        "## 2. Out-of-the-box summarization with Command-R\n",
        "\n",
        "First, let's see Command-R's out-of-the-box performance. It's a 128k-context model, so we can pass the full IMF report in a single call. We replicate the exact instructions from the original tweet (correcting for a minor typo) for enabling fair comparisons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXsYVkFaEn5l",
        "outputId": "ae9f5b33-656a-4d55-d382-e834a88d79a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated summary with 28746 tokens in, 388 tokens out\n",
            "\n",
            "--- Out-of-the-box summary with Command-R ---\n",
            "\n",
            "This Staff Discussion Note from the International Monetary Fund examines the potential impact of artificial intelligence (AI) on the global economy, with a focus on labor markets. \n",
            "\n",
            "**I. Introduction**: AI has the potential to revolutionize the economy, especially in advanced economies, which have a higher concentration of cognitive-intensive jobs. However, its effects are uncertain, and preparing for its impact is crucial.\n",
            "\n",
            "**II. AI Exposure and Complementarity**: Around 40% of global employment is exposed to AI. Advanced economies have the highest exposure (60%), followed by emerging markets (40%) and low-income countries (26%). Women and college-educated individuals are more exposed to AI but also better positioned to benefit from it. Older workers might struggle to adapt. \n",
            "\n",
            "**III. Worker Reallocation in the AI-Induced Transformation**: Historical data shows that college-educated workers are more likely to move into high AI-complementarity roles, while non-college-educated workers are less mobile. Older workers face challenges in reemployment and adapting to new technology. \n",
            "\n",
            "**IV. AI, Productivity, and Inequality**: AI may increase labor income inequality, especially if it strongly complements high-income workers' roles. However, broad productivity gains could lead to higher growth and incomes for most workers. Capital income and wealth inequality will likely rise due to increased returns on AI-related investments. \n",
            "\n",
            "**V. AI Preparedness**: A novel AI Preparedness Index measures countries' readiness for AI. Advanced and some emerging economies are relatively prepared, but low-income countries lag behind in digital infrastructure and human capital.\n",
            "\n",
            "**VI. Conclusions and Policy Considerations**: Countries must prioritize AI preparedness to maximize benefits and mitigate risks. Advanced economies should focus on regulation and innovation, while emerging and low-income countries should invest in foundational infrastructure and skills. Policies should ensure social cohesion and protect vulnerable workers during the transition.\n"
          ]
        }
      ],
      "source": [
        "prompt_template = \"\"\"\\\n",
        "## text\n",
        "{text}\n",
        "\n",
        "## instructions\n",
        "Step 1. Read the entire text from the first to the last page.\n",
        "Step 2. Create a summary of every chapter from the first to the last page.\n",
        "\n",
        "## summary\n",
        "\"\"\"\n",
        "\n",
        "prompt = prompt_template.format(text=text)\n",
        "resp = co.chat(\n",
        "  message=prompt,\n",
        "  model=co_model,\n",
        "  temperature=0.3,\n",
        "  return_prompt=True\n",
        ")\n",
        "\n",
        "num_tokens_in = co.tokenize(resp.prompt).length\n",
        "num_tokens_out = resp.meta[\"billed_units\"][\"output_tokens\"]\n",
        "print(f\"Generated summary with {num_tokens_in} tokens in, {num_tokens_out} tokens out\")\n",
        "print()\n",
        "print(\"--- Out-of-the-box summary with Command-R ---\")\n",
        "print()\n",
        "print(resp.text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLZsodOG41bb"
      },
      "source": [
        "<a id=\"introduce-citations-to-the-summary-for-grounding\"></a>\n",
        "<a name=\"introduce-citations-to-the-summary-for-grounding\"></a>\n",
        "## 3. Introduce citations to the summary for grounding\n",
        "\n",
        "When summarizing long documents, introducing citations is one simple method for checking the factuality of the summary without needing to read the full document.\n",
        "\n",
        "\n",
        "We've trained Command-R to introduce citations whenever prompted by our grounded generations instructions. Triggering this grounded mode is straightforward. Starting from the previous snippet, we only need to make two changes:\n",
        "1. Pass our text to the `documents` argument\n",
        "2. Pass our instructions to the `message` argument\n",
        "\n",
        "For more information on how to enable grounded generation via our `co.chat` API, please refer to our [documentation](https://docs.cohere.com/reference/chat).\n",
        "\n",
        "Finally, note that we chunk the IMF report into multiple documents before passing them to `co.chat`. This isn't necessary (`co.chat` annotates citations at the character level), but allows for more human-readable citations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-nrG21VEn9a",
        "outputId": "0edfc184-32cc-4f84-a5a5-aafce84a6339"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated summary with 29070 tokens in, 507 tokens out\n",
            "\n",
            "--- Summary with citations using RAG in Command-R ---\n",
            "\n",
            "## Executive Summary\n",
            "The discussion paper details how the adoption of artificial intelligence (AI) will profoundly affect the global economy, with significant implications for labour markets. AI exposure is highest in advanced economies, creating both risks and opportunities. Women and educated workers are most exposed, while older workers may struggle with the transition to AI. AI will affect wealth and income inequality, with those in high-income positions most poised to benefit. However, the overall impact is uncertain, dependent on how AI is integrated and regulated. \n",
            "\n",
            "## Introduction\n",
            "The paper introduces the subject of the future of work and AI, explaining how it promises to boost productivity but also threatens jobs. AI's impact on economies and societies is unclear, but it is likely to be profound. \n",
            "\n",
            "## AI Exposure and Complementarity\n",
            "This section defines the conceptual framework of AI exposure and its potential complementarity with human labour. Exposure is highest in advanced economies, especially in roles requiring complex cognitive tasks. An index is introduced to measure potential complementarity, finding that judges, surgeons and lawyers have high exposure and high complementarity. \n",
            "\n",
            "## Worker Reallocation in the AI-Induced Transformation\n",
            "Here, the historical mobility of workers across different occupations is analysed to predict future adaptability. The most educated and younger workers have shown greater adaptability, with college-educated individuals more able to move into high-complementarity roles. Older workers may struggle with reemployment and adapting to new technology. \n",
            "\n",
            "## AI, Productivity and Inequality\n",
            "A model is used to evaluate AI's impact on the economy and inequality, finding that it will cause a reshuffle across sectors and varying impacts on labour and capital income. The direct relationship between AI and income is complex, depending on numerous factors. However, overall national income is expected to increase, creating a potential widening of the global income disparity. \n",
            "\n",
            "## AI Preparedness\n",
            "This section proposes an AI Preparedness Index, comprised of four categories: digital infrastructure, innovation and economic integration, human capital and labour market policies, and regulation and ethics. The index is used to assess economies' readiness for AI, finding advanced economies are generally better prepared. However, significant differences are seen across countries, with foundational infrastructure and human capital investment needed in emerging market and developing economies. \n",
            "\n",
            "## Conclusions and Policy Considerations\n",
            "The paper concludes that AI adoption will generate significant variation in labour market outcomes across countries. Harnessing its benefits requires a proactive approach from policymakers, including investment in digital infrastructure and regulation. AI's ethical and data security challenges require international cooperation.\n"
          ]
        }
      ],
      "source": [
        "summarize_preamble = \"\"\"\\\n",
        "You will receive a series of text fragments from an article that are presented in chronological order. \\\n",
        "As the assistant, you must generate responses to user's requests based on the information given in the fragments. \\\n",
        "Ensure that your responses are accurate and truthful, and that you reference your sources where appropriate to answer \\\n",
        "the queries, regardless of their complexity.\\\n",
        "\"\"\"\n",
        "\n",
        "instructions = \"\"\"\\\n",
        "## instructions\n",
        "Step 1. Read the entire text from the first to the last page.\n",
        "Step 2. Create a summary of every chapter from the first to the last page.\n",
        "\"\"\"\n",
        "\n",
        "# Chunk long text into multiple chunks for readable citations\n",
        "chunked = build_simple_chunks(text, n_sentences=30)\n",
        "# Use `message` and `documents` arguments to trigger grounded generation\n",
        "resp = co.chat(\n",
        "  preamble=summarize_preamble,\n",
        "  message=instructions,\n",
        "  documents=[{\"text\": chunk} for chunk in chunked],\n",
        "  model=co_model,\n",
        "  temperature=0.3,\n",
        "  return_prompt=True\n",
        ")\n",
        "# Note: the grounded generation pipeline takes longer when documents are chunked\n",
        "# more finely. For latency-sensitive applications, try tuning the size of chunks!\n",
        "\n",
        "num_tokens_in = co.tokenize(resp.prompt).length\n",
        "num_tokens_out = resp.meta[\"billed_units\"][\"output_tokens\"]\n",
        "print(f\"Generated summary with {num_tokens_in} tokens in, {num_tokens_out} tokens out\")\n",
        "print()\n",
        "print(\"--- Summary with citations using grounded generation in Command-R ---\")\n",
        "print()\n",
        "print(resp.text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oWRUqAgUKfX"
      },
      "source": [
        "Let's display the citations inside our answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vq-F26hCUJjl",
        "outputId": "f41f5d9e-c3d1-425b-e940-feea85d3797d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## Executive Summary [1]\n",
            "The discussion note examines how artificial intelligence (AI) will affect the global economy [0, 1], with a focus on labour markets [0, 1, 2, 3, 12], and the varying susceptibility of different countries [0, 1, 3, 16, 17] to the benefits and drawbacks [0, 1, 2, 12, 14, 17] of AI. \n",
            "\n",
            "## Introduction [2]\n",
            "This section introduces the topic of AI and its uncertain impact on economies and societies [2, 4], focusing on the potential effects on labour markets. [0, 1, 2, 3] AI has the capacity to augment or replace [3] roles previously thought immune to automation [3], unlike previous technological advances. The net effect of AI on the economy and jobs will depend on how well countries innovate, adopt, and adapt [3, 12] to its use.\n",
            "\n",
            "## AI Exposure [2, 4] and Complementarity [2, 4, 5, 6, 7, 8, 9, 12]\n",
            "Around 40% of employment worldwide is exposed to AI [1, 6], with advanced economies [1, 6, 7] at greater risk [1, 6, 7] of automation but also in a better position to benefit from AI. [0, 1, 3, 6, 7] Women [7, 8] and college-educated individuals [1, 2, 7, 8] are the most exposed [7, 8] to AI, but also the most likely to benefit [7, 8] from it. Occupations with high exposure and high complementarity [5] are most likely to experience productivity growth. [5] \n",
            "\n",
            "## Worker Reallocation [3, 9, 10, 11, 12] in the AI-Induced Transformation\n",
            "Workers will adapt to AI demands [9, 12], with young, college-educated workers most able to adapt [2, 9, 10, 12], while older workers may struggle. [2, 10, 11] Jobs with high exposure and high complementarity [12] offer the best wage opportunities. [12] Historical patterns indicate that some workers will be unable to adapt [9] to AI-induced changes.\n",
            "\n",
            "## AI, Productivity and Inequality [0, 1, 3, 12, 13, 14]\n",
            "AI will affect income and wealth inequality. [0, 1, 3, 12, 14] Unlike previous technological advances, AI's displacements risks span all income levels. [1, 3, 8] The impact of AI on inequality depends on the balance between exposure and complementarity [13], and its boost to productivity. [13] Advanced economies may experience a polarising effect [7] from AI, with both positive and negative consequences. [7] However, overall AI adoption is likely to boost productivity [14] and increase total income. [14] \n",
            "\n",
            "## AI Preparedness [15, 16, 17, 18, 20, 21, 25]\n",
            "This section introduces an AI Preparedness Index [15, 16], which evaluates countries' readiness in four key areas: digital infrastructure [15, 16, 17], innovation and economic integration [15, 16], human capital and labour market policies [15, 16, 18], and regulation and ethics. [15, 16, 17, 18, 26, 27] Advanced economies [16, 26] and some emerging markets [16, 18, 26] are most prepared [16, 26] for AI. Foundational AI preparedness [17, 18], such as digital infrastructure [17, 18, 21] and human capital investment [17, 18, 20], is most important.\n",
            "\n",
            "## Conclusions [0, 17, 18, 20] and Policy Considerations [18, 20, 28, 31]\n",
            "Countries' ability to benefit from AI varies [0, 17], with advanced economies [0, 1, 6, 16, 17] and some emerging markets [0, 16, 18] best placed to take advantage. Policies must focus on equitable AI integration [18, 20, 28], preparing the next generation [18, 22], and supporting those at risk [2, 18, 22, 28] of negative consequences. International cooperation [18, 28] is required to address AI's ethical and data security challenges. [18, 28]\n"
          ]
        }
      ],
      "source": [
        "print(insert_citations(resp.text, resp.citations))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zC9Zt8ZXBZM"
      },
      "source": [
        "We can now visualise which section of the answer is based on which passage in the main text. Verifying factuality is straightforward: pick a section and verify that the relevant information is contained in the cited chunk.\n",
        "\n",
        "For instance, let's verify the statement\n",
        "```\n",
        "Around 40% of employment worldwide is exposed to AI [1, 6]\n",
        "```\n",
        "by checking its chunk:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADq2XJhlUnEI",
        "outputId": "7aea0f41-cd8a-4132-f7a7-48482549c962"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This conceptual framework is subject to several caveats. First, the index of Felten, Raj, and Seamans\n",
            "(2021) and the complementarity measure discussed in Box 1 offer only a relative interpretation. In other words,\n",
            "these measures tell us whether a given occupation is more or less exposed, or complementary, than others. Second, high complementarity can still result in displacement from occupations of workers who do not have the\n",
            "required skills or whose employers do not invest in the technology. Companies investing in these technologies\n",
            "earlier would solidify commercial advantages over competitors. In other words, while the analysis assumes that\n",
            "workers within the same occupation will be affected in the same way, there can be variation in the effects of AI. Firms that are more successful at integrating AI may increase their productivity more than competitors and pay\n",
            "higher wages, exacerbating intra-occupational inequality. Third, the conceptual framework provides only a\n",
            "static view of exposure and complementarity. In this regard, it does not speak to the existing or prospective\n",
            "availability of necessary IT infrastructure or to workers’ ability to acquire the needed skills or to relocate across\n",
            "different occupations. Neither does it take into account the effects of ongoing integration of AI and robotics. In\n",
            "addition, it does not factor in potential changes in societal preferences, which will also shape regulations and\n",
            "could make unsupervised AI acceptable in a growing number of contexts or ban its use in others. On the\n",
            "macroeconomic side, it does not account for adoption speed and the factors influencing adoption, including\n",
            "costs borne by firms compared with productivity benefits. The conceptual framework also does not factor in\n",
            "feedback effects, which, for example—through higher overall productivity as a result of AI adoption—could\n",
            "boost labor demand for most types of jobs, partially offsetting potential negative impacts of AI. The note applies this categorization to appraise the exposure of the current employment structure to AI\n",
            "for a large number of countries. The definitions are applied to 142 countries using the online International\n",
            "Labour Organization (ILO) employment database and an internationally consistent classification of occupations. To examine within-country variation, a more granular level of the categorization—based on more than 400\n",
            "occupation titles—is also applied to countries with good microdata coverage: two advanced economies (UK\n",
            "and US) and four emerging market economies (Brazil, Colombia, India, South Africa).4\n",
            "\n",
            "II.2 Cross-Country Differences\n",
            "About 40 percent of workers worldwide are in high-exposure occupations; the share is 60 percent in\n",
            "advanced economies, which indicates potentially large macroeconomic implications. Advanced\n",
            "economies have a greater share of high-exposure occupations, with either low or high complementarity, than\n",
            "emerging market economies and low-income countries (Figure 1, panel 1). In the average advanced economy,\n",
            "27 percent of employment is in high-exposure, high-complementarity occupations, 33 percent in high-exposure,\n",
            "low-complementarity jobs. In comparison, emerging market economies have corresponding shares of 16 and\n",
            "\n",
            "4 Specifically, the analysis of the 142 countries from the ILO database uses 72 sub-major occupation groups (2-digit level) of the\n",
            "International Standard Classification of Occupations (ISCO)-08 classification. The microdata analysis uses the 130 minor groups (3-\n",
            "digit) of the same classification for India and the 436 unit groups (4-digit) for the other five countries. See Annex 1 for details. STAFF DISCUSSION NOTES Gen-AI: Artificial Intelligence and the Future of Work\n",
            "INTERNATIONAL MONETARY FUND 8\n",
            "24 percent, respectively, and low-income countries have shares of 8 and 18 percent, respectively.5 A similar\n",
            "result emerges when looking at selected individual countries using more refined classifications (Figure 1, panel\n",
            "2). Almost 70 and 60 percent of UK and US employment, respectively, is in high-exposure occupations,\n",
            "approximately equally distributed between those that are high- and low-complementarity positions. Highexposure employment in emerging market economies ranges from 41 percent in Brazil to 26 percent in India. Figure 1. Employment Shares by AI Exposure and Complementarity: Country Groups and Selected\n",
            "Individual Countries\n",
            "1. Country Groups\n",
            "(Percent)\n",
            "2. Selected Countries\n",
            "(Percent)\n",
            "Sources: American Community Survey; Gran Encuesta Integrada de Hogares; India Periodic Labour Force Survey; International Labour\n",
            "Organization; Labour Market Dynamics in South Africa; Pesquisa Nacional por Amostra de Domicílios Contínua; UK Labour Force Survey; and IMF\n",
            "staff calculations. Note: Country labels use International Organization for Standardization (ISO) country codes. AEs = advanced economies; EMs = emerging market\n",
            "economies; LICs = low-income countries; World = all countries in the sample. \n"
          ]
        }
      ],
      "source": [
        "print(chunked[6])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQgmDucZYNUi"
      },
      "source": [
        "Seems convincing!\n",
        "By repeating such checks, it's straightforward to build trust in your summaries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnWyAyRI7U01"
      },
      "source": [
        "<a id=\"reduce-the-cost-of-summarization-calls\"></a>\n",
        "<a name=\"reduce-the-cost-of-summarization-calls\"></a>\n",
        "## 4. Reduce the cost of summarization calls\n",
        "\n",
        "Even though Command-R is an efficient, light-weight model, for some applications we may accept trading off some summarization quality for lower costs. To do this, we must reduce the amount of tokens sent to the model -- but how do we select the most relevant bits?\n",
        "\n",
        "We have a whole notebook dedicated to methods for reducing context length. Here, we call our 'text-rank' method to select maximally central chunks in a graph based on the chunk-to-chunk similarties. For more detail, please refer [to this cookbook](https://colab.research.google.com/drive/1zxSAbruOWwWJHNsj3N56uxZtUeiS7Evd)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BZZ_cc1EoEA",
        "outputId": "1a077f8e-0363-48fe-c99a-6b4783b2982d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated summary with 8456 tokens in, 619 tokens out\n",
            "\n",
            "--- Summary with citations using text-rank + RAG in Command-R ---\n",
            "\n",
            "## **Executive Summary** \n",
            "\n",
            "This Staff Discussion Note explores the impact of artificial intelligence (AI) on the global economy, particularly the labour market. It analyses AI exposure and complementarity across countries, worker reallocation, the effects of AI on productivity and inequality, and country AI preparedness. \n",
            "\n",
            "The note finds that advanced economies will feel the effects of AI sooner and more intensely than others due to their focus on cognitive-intensive roles. There are common patterns of AI exposure across countries, affecting women, the educated, and older workers differently. High AI exposure could lead to increased labour income inequality, while productivity gains could surge income levels for most workers. \n",
            "\n",
            "## **I. Introduction**\n",
            "\n",
            "The discussion note aims to analyse the effects of AI on the economy and labour markets, focusing on exposure and complementarity, worker transitions, AI impact on productivity and inequality, and AI preparedness. \n",
            "\n",
            "## **II. AI Exposure and Complementarity**\n",
            "\n",
            "This section explores the exposure of different countries and occupations to AI and their potential complementarity. The AI Occupational Exposure (AIOE) index of Felten, Raj, and Seamans (2021) is introduced, measuring the overlap between AI and human skills. It's noted that advanced economies have a larger share of high-exposure occupations than emerging markets and low-income countries. The UK, for example, has a large portion of professional and managerial occupations exposed to AI. \n",
            "\n",
            "## **III. Worker Reallocation in the AI-Induced Transformation**\n",
            "\n",
            "Here the long-term adaptability of workers to AI is discussed. Historical data analysis suggests workers generally switch between similar occupations, indicating an inability to adapt quickly to changing markets. However, some transitions between occupations with varying AI exposure levels also occur. College-educated workers have shown a better ability to move into high AI-complementarity roles. \n",
            "\n",
            "## **IV. AI, Productivity, and Inequality**\n",
            "\n",
            "Using a model-based approach, this section evaluates the impact of AI on the economy, focusing on labour displacement, complementarity, and productivity gains. AI may reduce labour income as tasks are substituted by AI capital. The analysis suggests that the overall effect on income levels will depend on the balance between labour income losses and productivity gains. In the UK, for example, capital income's influence grows with AI adoption, potentially increasing income and wealth inequality. \n",
            "\n",
            "## **V. AI Preparedness**\n",
            "\n",
            "This part of the note constructs an index to assess countries' preparedness for AI integration. The index evaluates digital infrastructure, human capital, innovation, and legal frameworks. It's suggested that advanced economies should focus on regulatory frameworks and supporting worker transitions, while emerging markets and low-income countries should prioritise digital infrastructure development.\n",
            "\n",
            "## **VI. Conclusions and Policy Considerations**\n",
            "\n",
            "The conclusion emphasises the need for proactive policymaking to manage the AI transition, including international cooperation to address ethical and data security issues. Policies should aim to train workers in new technologies, protect those at risk of disruption, and ensure social cohesion.\n"
          ]
        }
      ],
      "source": [
        "# First, we filter the original text down to a smaller amount of tokens.\n",
        "# This will reduce cost and improve latency\n",
        "num_tokens = 8192\n",
        "shortened = textrank(text, co, num_tokens, n_sentences_per_passage=30)\n",
        "\n",
        "# Then, we apply grounded generation to keep citations on our (now shorter) report\n",
        "chunked = build_simple_chunks(shortened)\n",
        "resp = co.chat(\n",
        "  message=instructions,\n",
        "  documents=[{\"text\": chunk} for chunk in chunked],\n",
        "  model=co_model,\n",
        "  temperature=0.3,\n",
        "  return_prompt=True\n",
        ")\n",
        "\n",
        "num_tokens_in = co.tokenize(resp.prompt).length\n",
        "num_tokens_out = resp.meta[\"billed_units\"][\"output_tokens\"]\n",
        "print(f\"Generated summary with {num_tokens_in} tokens in, {num_tokens_out} tokens out\")\n",
        "print()\n",
        "print(\"--- Summary with citations using text-rank + grounding in Command-R ---\")\n",
        "print()\n",
        "print(resp.text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBcnnR6MUG5z"
      },
      "source": [
        "The summary is looking convincing! In practice, the trade-off between cost-efficiency and performance should be considered carefully."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
