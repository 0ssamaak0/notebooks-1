{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import os\n",
    "import uuid\n",
    "from typing import List, Dict\n",
    "\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "co = cohere.Client(COHERE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbot component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chatbot:\n",
    "    def __init__(self, connectors: List[str]):\n",
    "        self.conversation_id = str(uuid.uuid4())\n",
    "        self.connectors = [{\"id\": c} for c in connectors]\n",
    "        \n",
    "\n",
    "    def generate_response(self, message: str):\n",
    "        response = co.chat(\n",
    "                        message=message,\n",
    "                        connectors=self.connectors,\n",
    "                        conversation_id=self.conversation_id,\n",
    "                        stream=True\n",
    "                        )\n",
    "\n",
    "        for event in response:\n",
    "                yield event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### App component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class App:\n",
    "    def __init__(self, chatbot: Chatbot):\n",
    "        self.chatbot = chatbot\n",
    "        \n",
    "    def run(self):\n",
    "        while True:\n",
    "            # Get the user message\n",
    "            message = input(\"User: \")\n",
    "\n",
    "            # Typing \"quit\" ends the conversation\n",
    "            if message.lower() == \"quit\":\n",
    "                print(\"Ending chat.\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"User: {message}\")\n",
    "\n",
    "            # Get the chatbot response\n",
    "            response = self.chatbot.generate_response(message)\n",
    "\n",
    "            # Print the chatbot response\n",
    "            print(\"Chatbot:\")\n",
    "            \n",
    "            documents = []\n",
    "            documents_flag = False\n",
    "            citations_flag = False\n",
    "            \n",
    "            for event in response:\n",
    "                # Documents\n",
    "                if event.event_type == \"search-results\":\n",
    "                    documents_flag = True\n",
    "                    documents = event.documents\n",
    "                    \n",
    "                # Text\n",
    "                if event.event_type == \"text-generation\":\n",
    "                    print(event.text, end=\"\")        \n",
    "\n",
    "                # Citations\n",
    "                if event.event_type == \"citation-generation\":\n",
    "                    if not citations_flag:\n",
    "                        print(\"\\n\\nCITATIONS:\")\n",
    "                        citations_flag = True\n",
    "                    print(event.citations)\n",
    "            \n",
    "            if documents_flag:\n",
    "                print(\"\\n\\nDOCUMENTS:\")\n",
    "                for d in documents:\n",
    "                    print(f'{d[\"title\"]} ({d[\"id\"]}). URL: {d[\"url\"]}')\n",
    "\n",
    "            print(f\"\\n{'-'*100}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run chatbot with Google Drive connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is prompt engineering\n",
      "Chatbot:\n",
      "Prompt engineering is about sending instructions to text generation models and obtaining responses. A prompt can consist of a single line of instruction, but the more specific it is, the more accurate you can expect the response to be. Each additional building block added to a prompt provides a different means of improving the quality of the response.\n",
      "\n",
      "When working with large language models (LLMs), prompt engineering opens up many possibilities for creativity. However, there are trade-offs in terms of performance, and outputs from LLMs are probabilistic, so a mechanism for validating outputs is necessary.\n",
      "\n",
      "CITATIONS:\n",
      "[{'start': 28, 'end': 99, 'text': 'sending instructions to text generation models and obtaining responses.', 'document_ids': ['demo-conn-gdrive-1x2p4k_0:3']}]\n",
      "[{'start': 126, 'end': 152, 'text': 'single line of instruction', 'document_ids': ['demo-conn-gdrive-1x2p4k_0:3', 'demo-conn-gdrive-1x2p4k_0:33']}]\n",
      "[{'start': 162, 'end': 235, 'text': 'more specific it is, the more accurate you can expect the response to be.', 'document_ids': ['demo-conn-gdrive-1x2p4k_0:33']}]\n",
      "[{'start': 252, 'end': 353, 'text': 'building block added to a prompt provides a different means of improving the quality of the response.', 'document_ids': ['demo-conn-gdrive-1x2p4k_0:33']}]\n",
      "[{'start': 373, 'end': 401, 'text': 'large language models (LLMs)', 'document_ids': ['demo-conn-gdrive-1x2p4k_1:15']}]\n",
      "[{'start': 422, 'end': 465, 'text': 'opens up many possibilities for creativity.', 'document_ids': ['demo-conn-gdrive-1x2p4k_1:15']}]\n",
      "[{'start': 485, 'end': 519, 'text': 'trade-offs in terms of performance', 'document_ids': ['demo-conn-gdrive-1x2p4k_1:15']}]\n",
      "[{'start': 525, 'end': 560, 'text': 'outputs from LLMs are probabilistic', 'document_ids': ['demo-conn-gdrive-1x2p4k_3:0']}]\n",
      "[{'start': 567, 'end': 613, 'text': 'mechanism for validating outputs is necessary.', 'document_ids': ['demo-conn-gdrive-1x2p4k_3:0']}]\n",
      "\n",
      "\n",
      "DOCUMENTS:\n",
      "Chaining Prompts (demo-conn-gdrive-1x2p4k_1:15). URL: https://docs.google.com/document/d/1oF20QD0lHNdYQp6F7sSyEC1grGErout4GIQn1JBUACo/edit?usp=drivesdk\n",
      "Evaluating Outputs (demo-conn-gdrive-1x2p4k_4:15). URL: https://docs.google.com/document/d/10x9mJOnEr62hg1IFxgAtD1aIFS4NXJ2l5Lt-UhJXLVg/edit?usp=drivesdk\n",
      "Validating Outputs (demo-conn-gdrive-1x2p4k_3:0). URL: https://docs.google.com/document/d/1wngAfCJY1IgD6H__4AkQXFfymKUpSeJL13TItbigdyA/edit?usp=drivesdk\n",
      "Constructing Prompts (demo-conn-gdrive-1x2p4k_0:3). URL: https://docs.google.com/document/d/1LGsOhBL02jwy5UUIS8tuv9G80FSn7vxeQYiiglsN9oY/edit?usp=drivesdk\n",
      "Constructing Prompts (demo-conn-gdrive-1x2p4k_0:33). URL: https://docs.google.com/document/d/1LGsOhBL02jwy5UUIS8tuv9G80FSn7vxeQYiiglsN9oY/edit?usp=drivesdk\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ending chat.\n"
     ]
    }
   ],
   "source": [
    "# Define connectors\n",
    "connectors = [\"demo-conn-gdrive-1x2p4k\"]\n",
    "\n",
    "# Create an instance of the Chatbot class by supplying the connectors\n",
    "chatbot = Chatbot(connectors)\n",
    "\n",
    "# Create an instance of the App class with the Chatbot instance\n",
    "app = App(chatbot)\n",
    "\n",
    "# Run the chatbot\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run chatbot with web search connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is LLM University\n",
      "Chatbot:\n",
      "LLM University (LLMU) is an online learning resource provided by Cohere that offers a comprehensive curriculum on natural language processing (NLP) using large language models. It caters to learners from all backgrounds, from beginners to advanced, and the courses are geared towards anyone excited about language processing, including those looking to build apps using language AI. The courses cover everything from the basics of LLMs to advanced topics like generative AI, with practical code examples to help learners solidify their knowledge. The hands-on exercises allow learners to build and deploy their own models.\n",
      "\n",
      "CITATIONS:\n",
      "[{'start': 15, 'end': 21, 'text': '(LLMU)', 'document_ids': ['web-search_1:0', 'web-search_0:4', 'web-search_1:2', 'web-search_1:3', 'web-search_0:3']}]\n",
      "[{'start': 28, 'end': 71, 'text': 'online learning resource provided by Cohere', 'document_ids': ['web-search_1:0']}]\n",
      "[{'start': 86, 'end': 147, 'text': 'comprehensive curriculum on natural language processing (NLP)', 'document_ids': ['web-search_1:0']}]\n",
      "[{'start': 180, 'end': 219, 'text': 'caters to learners from all backgrounds', 'document_ids': ['web-search_1:2']}]\n",
      "[{'start': 226, 'end': 247, 'text': 'beginners to advanced', 'document_ids': ['web-search_1:0']}]\n",
      "[{'start': 257, 'end': 324, 'text': 'courses are geared towards anyone excited about language processing', 'document_ids': ['web-search_1:2']}]\n",
      "[{'start': 353, 'end': 382, 'text': 'build apps using language AI.', 'document_ids': ['web-search_1:2']}]\n",
      "[{'start': 421, 'end': 473, 'text': 'basics of LLMs to advanced topics like generative AI', 'document_ids': ['web-search_1:0', 'web-search_1:2']}]\n",
      "[{'start': 480, 'end': 503, 'text': 'practical code examples', 'document_ids': ['web-search_1:2']}]\n",
      "[{'start': 521, 'end': 546, 'text': 'solidify their knowledge.', 'document_ids': ['web-search_1:2']}]\n",
      "[{'start': 551, 'end': 569, 'text': 'hands-on exercises', 'document_ids': ['web-search_1:3']}]\n",
      "[{'start': 588, 'end': 622, 'text': 'build and deploy their own models.', 'document_ids': ['web-search_1:3']}]\n",
      "\n",
      "\n",
      "DOCUMENTS:\n",
      "Introducing LLM University — Your Go-To Learning Resource for NLP🎓 (web-search_1:0). URL: https://txt.cohere.com/llm-university/\n",
      "LLM University (LLMU) | Cohere (web-search_0:4). URL: https://docs.cohere.com/docs/llmu\n",
      "Introducing LLM University — Your Go-To Learning Resource for NLP🎓 (web-search_1:2). URL: https://txt.cohere.com/llm-university/\n",
      "Introducing LLM University — Your Go-To Learning Resource for NLP🎓 (web-search_1:3). URL: https://txt.cohere.com/llm-university/\n",
      "LLM University (LLMU) | Cohere (web-search_0:3). URL: https://docs.cohere.com/docs/llmu\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ending chat.\n"
     ]
    }
   ],
   "source": [
    "# Define connectors\n",
    "connectors = [\"web-search\"]\n",
    "\n",
    "# Create an instance of the Chatbot class by supplying the connectors\n",
    "chatbot = Chatbot(connectors)\n",
    "\n",
    "# Create an instance of the App class with the Chatbot instance\n",
    "app = App(chatbot)\n",
    "\n",
    "# Run the chatbot\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run chatbot with multiple connectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is chain of thought prompting\n",
      "Chatbot:\n",
      "Chain of thought prompting is a technique used to help LLMs (Large Language Models) perform complex reasoning by breaking down problems into logical, bite-sized chunks. This method encourages LLMs to produce intermediate reasoning steps before delivering a final answer to a multi-step problem. The idea is that a model-generated chain of thought would mimic an intuitive thought process when working through a multi-step reasoning problem. \n",
      "\n",
      "This concept was introduced by Wei et al. in 2023, and has been found to be particularly useful in improving LLMs' performance at complex arithmetic, commonsense, and symbolic reasoning tasks.\n",
      "\n",
      "CITATIONS:\n",
      "[{'start': 55, 'end': 83, 'text': 'LLMs (Large Language Models)', 'document_ids': ['web-search_9:2']}]\n",
      "[{'start': 92, 'end': 109, 'text': 'complex reasoning', 'document_ids': ['web-search_7:2', 'web-search_9:2', 'web-search_8:7', 'web-search_8:1']}]\n",
      "[{'start': 113, 'end': 168, 'text': 'breaking down problems into logical, bite-sized chunks.', 'document_ids': ['web-search_7:2', 'web-search_9:2']}]\n",
      "[{'start': 208, 'end': 269, 'text': 'intermediate reasoning steps before delivering a final answer', 'document_ids': ['web-search_3:2', 'demo-conn-gdrive-1x2p4k_11:20', 'web-search_7:2', 'demo-conn-gdrive-1x2p4k_10:6', 'web-search_8:7', 'web-search_8:1']}]\n",
      "[{'start': 275, 'end': 294, 'text': 'multi-step problem.', 'document_ids': ['web-search_3:2', 'web-search_8:7']}]\n",
      "[{'start': 314, 'end': 387, 'text': 'model-generated chain of thought would mimic an intuitive thought process', 'document_ids': ['web-search_3:2', 'web-search_8:7']}]\n",
      "[{'start': 474, 'end': 484, 'text': 'Wei et al.', 'document_ids': ['demo-conn-gdrive-1x2p4k_11:20', 'web-search_9:2', 'demo-conn-gdrive-1x2p4k_10:6']}]\n",
      "[{'start': 488, 'end': 492, 'text': '2023', 'document_ids': ['demo-conn-gdrive-1x2p4k_10:6']}]\n",
      "[{'start': 573, 'end': 635, 'text': 'complex arithmetic, commonsense, and symbolic reasoning tasks.', 'document_ids': ['web-search_7:2', 'web-search_9:2']}]\n",
      "\n",
      "\n",
      "DOCUMENTS:\n",
      "Language Models Perform Reasoning via Chain of Thought – Google Research Blog (web-search_3:2). URL: https://blog.research.google/2022/05/language-models-perform-reasoning-via.html\n",
      "Constructing Prompts (demo-conn-gdrive-1x2p4k_11:20). URL: https://docs.google.com/document/d/1LGsOhBL02jwy5UUIS8tuv9G80FSn7vxeQYiiglsN9oY/edit?usp=drivesdk\n",
      "Let’s Think Step by Step: Advanced Reasoning in Business with Chain-of-Thought Prompting | by Jerry Cuomo | Aug, 2023 | Medium (web-search_7:2). URL: https://medium.com/@JerryCuomo/lets-think-step-by-step-advanced-reasoning-in-business-with-chain-of-thought-prompting-dd5ae8a6008\n",
      "Constructing Prompts (demo-conn-gdrive-1x2p4k_11:30). URL: https://docs.google.com/document/d/1LGsOhBL02jwy5UUIS8tuv9G80FSn7vxeQYiiglsN9oY/edit?usp=drivesdk\n",
      "Chain-of-Thought Prompting: Helping LLMs Learn by Example | Deepgram (web-search_9:2). URL: https://deepgram.com/learn/chain-of-thought-prompting-guide\n",
      "Chaining Prompts (demo-conn-gdrive-1x2p4k_10:6). URL: https://docs.google.com/document/d/1oF20QD0lHNdYQp6F7sSyEC1grGErout4GIQn1JBUACo/edit?usp=drivesdk\n",
      "Master Prompting Concepts: Chain of Thought Prompting (web-search_8:7). URL: https://promptengineering.org/master-prompting-concepts-chain-of-thought-prompting/\n",
      "Chaining Prompts (demo-conn-gdrive-1x2p4k_10:7). URL: https://docs.google.com/document/d/1oF20QD0lHNdYQp6F7sSyEC1grGErout4GIQn1JBUACo/edit?usp=drivesdk\n",
      "Master Prompting Concepts: Chain of Thought Prompting (web-search_8:1). URL: https://promptengineering.org/master-prompting-concepts-chain-of-thought-prompting/\n",
      "Chaining Prompts (demo-conn-gdrive-1x2p4k_10:0). URL: https://docs.google.com/document/d/1oF20QD0lHNdYQp6F7sSyEC1grGErout4GIQn1JBUACo/edit?usp=drivesdk\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ending chat.\n"
     ]
    }
   ],
   "source": [
    "# Define connectors\n",
    "connectors = [\"demo-conn-gdrive-1x2p4k\", \"web-search\"]\n",
    "\n",
    "# Create an instance of the Chatbot class by supplying the connectors\n",
    "chatbot = Chatbot(connectors)\n",
    "\n",
    "# Create an instance of the App class with the Chatbot instance\n",
    "app = App(chatbot)\n",
    "\n",
    "# Run the chatbot\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
